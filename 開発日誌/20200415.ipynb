{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"Using TensorFlow backend.\nData loaded!!\nTraining data amounts :3800\nTest data amounts :200\n"}],"source":["\"\"\"\n","Tensorflowによるオートエンコーダの実装\n","思い出しがてらの作成なのでコメントが膨大…\n","\n","2020/04/13時点 ResourceExhaustedErrorで動作せず\n","マシン能力不足？\n","\"\"\"\n","\n","\n","#%%\n","# cording = UTF-8\n","import os\n","import re\n","import random\n","import copy\n","import scipy\n","import librosa #無くしたい\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import sklearn\n","import keras\n","import tensorflow\n","\n","####################################初期化####################################\n","aug_amount = 100    #ファイルごとのAugmentationの回数\n","lr = 1e-01          #初期学習率\n","#alpha = 1e-03       #L2正則化の係数\n","#dr_rate = 0.3       #ドロップアウト率\n","batch_size = 50\n","epochs = 100\n","encode_dim = 1000   #オートエンコーダの圧縮次元\n","\n","#ディレクトリの初期化\n","base_dir = \"../\"\n","data_dir =os.path.join(base_dir,\"data\")\n","ok_dir = os.path.join(data_dir,\"OK\")\n","ng_dir = os.path.join(data_dir,\"NG\")\n","env_dir = os.path.join(data_dir,\"environment\")\n","\n","####################################関数定義###################################\n","\n","#対象ディレクトリのファイル一覧を取得\n","def get_file_list(dir):\n","    path = dir\n","    file_list = os.listdir(path)\n","    print(\"get file_list :{}\".format(file_list))\n","    return file_list\n","\n","#対象ディレクトリの最大ファイルをサーチ\n","def wav_search(dir,f_list):\n","    #呼び出されるごとに初期化する\n","    wave_list = []\n","    file_size = 0\n","    \n","    return_path = os.path.abspath('./')\n","    \n","    os.chdir(dir)\n","    for i in f_list:\n","        search_index = re.search('.wav',i)\n","        if search_index:\n","            wave_list .append(i)\n","            if os.path.getsize(i) > file_size:\n","                file_size = os.path.getsize(i)\n","                largest_file = i\n","        \n","    os.chdir(return_path)   #カレントディレクトリを戻す\n","    print(\"get file :{0} ,file size:{1}\"\\\n","        .format(largest_file,file_size))\n","    return wave_list,largest_file,file_size\n","\n","#オーディオファイルの読み込み サンプルレート44.1kHz、モノラルで固定\n","def load_wav(dir,file):\n","    #呼び出されるごとに初期化する\n","    wf = np.arange(0)\n","\n","    f_path = os.path.join(dir,file)\n","    wf,sp_rate = librosa.load(f_path,sr=44100,mono = True)\n","    del sp_rate\n","    return wf\n","\n","#スペクトログラムの取得 パワースペクトラムのまま処理するならlibrosa不要\n","def get_spg(wf):\n","    spg = np.arange(0)\n","    sp_f,sp_t,spg = scipy.signal.spectrogram(wf,fs=44100,\n","        window = np.hamming(1024),nfft =1024)\n","    spg = librosa.power_to_db(spg)\n","    spg =spg.astype('float16')\n","    return sp_f,sp_t,spg\n","\n","#Augmentationの処理\n","def aug_process(frame,dir,wave_list,env_file,):\n","    #呼び出されるごとに初期化する\n","    length = 0\n","    count = 0\n","    wf = np.arange(0)\n","\n","    length = int(frame * 1.2)\n","    for i in wave_list:\n","        wf = load_wav(dir,i)\n","        for j in range(aug_amount):\n","            start = random.randint(0,len(env_file)-length)\n","            aug_wav = copy.deepcopy(env_file[start : start + length])\n","            del start\n","            start = random.randint(0,len(aug_wav) - len(wf))\n","            aug_wav = aug_wav + random.gauss(1,0.05)\n","            aug_wav[ start:start + len(wf) ] = \\\n","                aug_wav[ start : start + len(wf) ] + wf\n","            sp_f,sp_t,spg = get_spg(aug_wav)\n","            spg = spg.reshape(1,len(sp_f),len(sp_t))\n","            try:\n","                X_data\n","            except:\n","                X_data = copy.deepcopy(spg)\n","            else:\n","                X_data = np.vstack((X_data,spg))\n","            del start,aug_wav,sp_f,sp_t,spg\n","            count = count + 1\n","        del wf\n","        print(\"Augmentation done! total count = {}\".format(count))\n","\n","    return X_data\n","\n","#データセットの作成 ここまでの関数は全部ここに集約される\n","#最大ファイルサイズに合わせてフレームサイズを定義し\n","#OK・NG各データセットを作成後、結合する\n","\n","def new_dataset(aug,ok_dir,ng_dir,env_dir):\n","    #OKNGそれぞれのファイルリストと最大ファイルを取得\n","    ok_filelist = get_file_list(ok_dir)\n","    ok_wave_list,ok_largeest_name,ok_largest_size = wav_search(ok_dir,ok_filelist)\n","    ng_filelist = get_file_list(ng_dir)\n","    ng_wave_list,ng_largeest_name,ng_largest_size = wav_search(ng_dir,ng_filelist)\n","\n","    #OKNGの最大を比較\n","    if ok_largest_size>ng_largest_size:\n","        largest_dir = ok_dir\n","        lergest_name = ok_largeest_name\n","        print(\"largetst:OK\")\n","    else:\n","        largest_dir = ng_dir\n","        lergest_name = ng_largeest_name\n","        print(\"largetst:NG\")\n","\n","    #最大フレームサイズを取得\n","    wf = load_wav(largest_dir,lergest_name)\n","    frame = int(len(wf))\n","    #wf = np.insert(wf,frame,np.empty(int(frame*0.2))) #1.2倍する\n","    #sp_f,sp_t,spg = get_spg(wf) \n","    #X_initsize = (len(sp_f),len(sp_t))\n","    #del wf,sp_f,sp_t,spg\n","    del wf\n","\n","    #環境音データをロード\n","    env_data = load_wav(env_dir,\"env.wav\")\n","    \n","    #OKデータセット作成\n","    X_ok = copy.deepcopy(\n","        aug_process(frame,ok_dir,ok_wave_list,env_data)\n","        )\n","    y_ok = np.zeros(len(X_ok),dtype = 'bool')\n","\n","    #NGデータセット作成\n","    X_ng = copy.deepcopy(\n","        aug_process(frame,ng_dir,ng_wave_list,env_data)\n","        )\n","    y_ng = np.ones(len(X_ng),dtype = 'bool')\n","\n","    #データセットの結合\n","    X_data = np.vstack((X_ok,X_ng))\n","    y_data = np.append(y_ok,y_ng)\n","    del X_ok,y_ok,X_ng,y_ng\n","\n","    return X_data,y_data\n","\n","#OKNGが混在したデータからFalseのみを分離する\n","def mixed_to_sprit(X_mixed,y_mixed):\n","    #呼び出されるごとに初期化する\n","    try:\n","        X_sprit\n","    except:\n","        pass    #X_spritが存在しなければ何もしない\n","    else:\n","        del X_sprit #前のデータを消去する\n","\n","    for i in range(len(X_mixed)):\n","        if y_mixed[i] == False:\n","            try:\n","                X_sprit\n","            except: #X_spritを生成する\n","                X_sprit = copy.deepcopy(X_mixed[i])\n","                X_sprit = X_sprit.reshape(1,X_mixed.shape[1])\n","            else:   #既存のX_spritに追加する 前段の例外処理はここを避けるため\n","                X_sprit = np.vstack(\n","                    (X_sprit,X_mixed[i].reshape(1,X_mixed.shape[1]))\n","                    )\n","\n","    return X_sprit\n","\n","###################################メイン処理###################################\n","\n","#データセット読み込み なければ作る\n","if os.path.exists(os.path.join(data_dir,'dataset.npz')) == False:\n","    X_data,y_data = new_dataset(aug_amount,ok_dir,ng_dir,env_dir)\n","    np.savez_compressed(os.path.join(data_dir,'dataset.npz'),\n","        X = X_data,y = y_data)\n","    print(\"Data set saved! ../data/dataset.npz\")\n","else:\n","    load_data = np.load(os.path.join(data_dir,'dataset.npz'))\n","    X_data =load_data['X']\n","    y_data = load_data['y']\n","    del load_data\n","    print(\"Data loaded!!\")\n","\n","#データ前処理 trainとtestを分離\n","from sklearn.model_selection import train_test_split\n","X_shape = X_data.shape[1:]\n","X_data = X_data.reshape(len(X_data),-1) #アフィン変換\n","X_train,X_test,y_train,y_test = \\\n","    train_test_split(X_data,y_data,test_size=0.05)\n","print(\n","\"Training data amounts :{0}\\n\\\n","Test data amounts :{1}\"\\\n",".format(len(y_train),len(y_test))\n",")\n","del X_data,y_data\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"X_train for Autoencoder was splited!!\namount/shape:(1912, 121068)\n"}],"source":["#X_trainからOKデータ(False)だけを抽出する\n","\n","X_train_ae = mixed_to_sprit(X_train,y_train)\n","print(\n","\"X_train for Autoencoder was splited!!\\n\\\n","amount/shape:{0}\"\n",".format(X_train_ae.shape)\n",")\n",""]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Epoch 1/100\n1912/1912 [==============================] - 202s 105ms/step - loss: -1777707999119.8704\nEpoch 2/100\n1912/1912 [==============================] - 198s 104ms/step - loss: -16665129876270.0586\nEpoch 3/100\n1912/1912 [==============================] - 198s 104ms/step - loss: -51051286557751.7031\nEpoch 4/100\n1912/1912 [==============================] - 201s 105ms/step - loss: -105449950506579.5469\nEpoch 5/100\n1912/1912 [==============================] - 200s 105ms/step - loss: -179592253791124.8750\nEpoch 6/100\n1912/1912 [==============================] - 201s 105ms/step - loss: -273070868318010.9062\nEpoch 7/100\n1912/1912 [==============================] - 204s 106ms/step - loss: -385560476980862.3750\nEpoch 8/100\n1912/1912 [==============================] - 202s 105ms/step - loss: -516665427643679.0625\nEpoch 9/100\n1912/1912 [==============================] - 202s 106ms/step - loss: -666167164566592.2500\nEpoch 10/100\n1912/1912 [==============================] - 198s 104ms/step - loss: -833624318998656.5000\nEpoch 11/100\n1912/1912 [==============================] - 200s 105ms/step - loss: -1018881304338603.3750\nEpoch 12/100\n1912/1912 [==============================] - 220s 115ms/step - loss: -1221590188924825.2500\nEpoch 13/100\n1912/1912 [==============================] - 217s 113ms/step - loss: -1441433142088725.5000\nEpoch 14/100\n1912/1912 [==============================] - 221s 115ms/step - loss: -1678232661095617.0000\nEpoch 15/100\n1912/1912 [==============================] - 222s 116ms/step - loss: -1931780701447343.7500\nEpoch 16/100\n1912/1912 [==============================] - 220s 115ms/step - loss: -2201772070983774.2500\nEpoch 17/100\n1912/1912 [==============================] - 222s 116ms/step - loss: -2487878078631953.0000\nEpoch 18/100\n1912/1912 [==============================] - 222s 116ms/step - loss: -2790014616066416.5000\nEpoch 19/100\n1912/1912 [==============================] - 220s 115ms/step - loss: -3107665715943929.5000\nEpoch 20/100\n1912/1912 [==============================] - 222s 116ms/step - loss: -3440841809621386.5000\nEpoch 21/100\n1912/1912 [==============================] - 223s 116ms/step - loss: -3789456453300618.5000\nEpoch 22/100\n1912/1912 [==============================] - 221s 116ms/step - loss: -4153153588127718.5000\nEpoch 23/100\n1912/1912 [==============================] - 221s 116ms/step - loss: -4531856559774956.0000\nEpoch 24/100\n1912/1912 [==============================] - 225s 118ms/step - loss: -4925104647078025.0000\nEpoch 25/100\n1912/1912 [==============================] - 231s 121ms/step - loss: -5332910448532784.0000\nEpoch 26/100\n1912/1912 [==============================] - 232s 121ms/step - loss: -5755288774138910.0000\nEpoch 27/100\n1912/1912 [==============================] - 230s 120ms/step - loss: -6191724397418179.0000\nEpoch 28/100\n1912/1912 [==============================] - 232s 121ms/step - loss: -6641768978932089.0000\nEpoch 29/100\n1912/1912 [==============================] - 231s 121ms/step - loss: -7105701626411548.0000\nEpoch 30/100\n1912/1912 [==============================] - 233s 122ms/step - loss: -7583477843029451.0000\nEpoch 31/100\n1912/1912 [==============================] - 234s 123ms/step - loss: -8074496318201685.0000\nEpoch 32/100\n1912/1912 [==============================] - 232s 121ms/step - loss: -8579115856910567.0000\nEpoch 33/100\n1912/1912 [==============================] - 232s 121ms/step - loss: -9096391641041180.0000\nEpoch 34/100\n1912/1912 [==============================] - 231s 121ms/step - loss: -9627162650448574.0000\nEpoch 35/100\n1912/1912 [==============================] - 230s 120ms/step - loss: -10170413033268058.0000\nEpoch 36/100\n1912/1912 [==============================] - 231s 121ms/step - loss: -10726162564993658.0000\nEpoch 37/100\n1912/1912 [==============================] - 231s 121ms/step - loss: -11294503986144362.0000\nEpoch 38/100\n1912/1912 [==============================] - 232s 121ms/step - loss: -11875129500090300.0000\nEpoch 39/100\n1912/1912 [==============================] - 232s 121ms/step - loss: -12468338804348062.0000\nEpoch 40/100\n1912/1912 [==============================] - 232s 122ms/step - loss: -13073752927581308.0000\nEpoch 41/100\n1912/1912 [==============================] - 232s 121ms/step - loss: -13691109770084694.0000\nEpoch 42/100\n1912/1912 [==============================] - 233s 122ms/step - loss: -14320040985624026.0000\nEpoch 43/100\n1912/1912 [==============================] - 233s 122ms/step - loss: -14961492550854698.0000\nEpoch 44/100\n1912/1912 [==============================] - 234s 122ms/step - loss: -15614087220043810.0000\nEpoch 45/100\n1912/1912 [==============================] - 231s 121ms/step - loss: -16278472434801694.0000\nEpoch 46/100\n1912/1912 [==============================] - 232s 121ms/step - loss: -16955136944211428.0000\nEpoch 47/100\n1912/1912 [==============================] - 233s 122ms/step - loss: -17642028713084936.0000\nEpoch 48/100\n1912/1912 [==============================] - 231s 121ms/step - loss: -18340714457660620.0000\nEpoch 49/100\n1912/1912 [==============================] - 231s 121ms/step - loss: -19049628457943792.0000\nEpoch 50/100\n1912/1912 [==============================] - 231s 121ms/step - loss: -19770241577375016.0000\nEpoch 51/100\n1912/1912 [==============================] - 233s 122ms/step - loss: -20501693669008832.0000\nEpoch 52/100\n1912/1912 [==============================] - 233s 122ms/step - loss: -21243875500954716.0000\nEpoch 53/100\n1912/1912 [==============================] - 232s 121ms/step - loss: -21996951876858388.0000\nEpoch 54/100\n1912/1912 [==============================] - 232s 122ms/step - loss: -22760928825847588.0000\nEpoch 55/100\n1912/1912 [==============================] - 234s 123ms/step - loss: -23534598963428692.0000\nEpoch 56/100\n1912/1912 [==============================] - 233s 122ms/step - loss: -24320178764531380.0000\nEpoch 57/100\n1912/1912 [==============================] - 231s 121ms/step - loss: -25115763366233436.0000\nEpoch 58/100\n1912/1912 [==============================] - 231s 121ms/step - loss: -25921620417778232.0000\nEpoch 59/100\n1912/1912 [==============================] - 232s 121ms/step - loss: -26737418858504088.0000\nEpoch 60/100\n1912/1912 [==============================] - 233s 122ms/step - loss: -27564355993658680.0000\nEpoch 61/100\n1912/1912 [==============================] - 231s 121ms/step - loss: -28399998537824112.0000\nEpoch 62/100\n1912/1912 [==============================] - 232s 121ms/step - loss: -29245915225558920.0000\nEpoch 63/100\n1912/1912 [==============================] - 230s 120ms/step - loss: -30103658296680620.0000\nEpoch 64/100\n1912/1912 [==============================] - 229s 120ms/step - loss: -30969486881847152.0000\nEpoch 65/100\n1912/1912 [==============================] - 230s 120ms/step - loss: -31845760474805028.0000\nEpoch 66/100\n1912/1912 [==============================] - 231s 121ms/step - loss: -32731796222926952.0000\nEpoch 67/100\n1912/1912 [==============================] - 230s 120ms/step - loss: -33627090384054932.0000\nEpoch 68/100\n1912/1912 [==============================] - 232s 122ms/step - loss: -34532675529426884.0000\nEpoch 69/100\n1912/1912 [==============================] - 231s 121ms/step - loss: -35448607877738684.0000\nEpoch 70/100\n1912/1912 [==============================] - 232s 122ms/step - loss: -36373332179101600.0000\nEpoch 71/100\n1912/1912 [==============================] - 232s 121ms/step - loss: -37308669939928216.0000\nEpoch 72/100\n1912/1912 [==============================] - 232s 121ms/step - loss: -38251675385465528.0000\nEpoch 73/100\n1912/1912 [==============================] - 233s 122ms/step - loss: -39205127507811288.0000\nEpoch 74/100\n1912/1912 [==============================] - 235s 123ms/step - loss: -40167125914223688.0000\nEpoch 75/100\n1912/1912 [==============================] - 236s 124ms/step - loss: -41138169445386528.0000\nEpoch 76/100\n1912/1912 [==============================] - 236s 124ms/step - loss: -42119118123574384.0000\nEpoch 77/100\n1912/1912 [==============================] - 236s 124ms/step - loss: -43109550264764904.0000\nEpoch 78/100\n1912/1912 [==============================] - 236s 123ms/step - loss: -44108594120883680.0000\nEpoch 79/100\n1912/1912 [==============================] - 236s 123ms/step - loss: -45116804326755544.0000\nEpoch 80/100\n1912/1912 [==============================] - 236s 123ms/step - loss: -46135400594688216.0000\nEpoch 81/100\n1912/1912 [==============================] - 235s 123ms/step - loss: -47161239067025376.0000\nEpoch 82/100\n1912/1912 [==============================] - 236s 123ms/step - loss: -48196399905150456.0000\nEpoch 83/100\n1912/1912 [==============================] - 235s 123ms/step - loss: -49241159959240944.0000\nEpoch 84/100\n1912/1912 [==============================] - 235s 123ms/step - loss: -50293477165531272.0000\nEpoch 85/100\n1912/1912 [==============================] - 236s 123ms/step - loss: -51355877962158368.0000\nEpoch 86/100\n1912/1912 [==============================] - 236s 123ms/step - loss: -52427244489537944.0000\nEpoch 87/100\n1912/1912 [==============================] - 237s 124ms/step - loss: -53506521493074448.0000\nEpoch 88/100\n1912/1912 [==============================] - 237s 124ms/step - loss: -54596170182212192.0000\nEpoch 89/100\n1912/1912 [==============================] - 238s 124ms/step - loss: -55692776826192904.0000\nEpoch 90/100\n1912/1912 [==============================] - 235s 123ms/step - loss: -56798256931011512.0000\nEpoch 91/100\n1912/1912 [==============================] - 236s 124ms/step - loss: -57912283297433536.0000\nEpoch 92/100\n1912/1912 [==============================] - 238s 125ms/step - loss: -59035206428035904.0000\nEpoch 93/100\n1912/1912 [==============================] - 238s 125ms/step - loss: -60167687994877584.0000\nEpoch 94/100\n1912/1912 [==============================] - 238s 124ms/step - loss: -61307968323800072.0000\nEpoch 95/100\n1912/1912 [==============================] - 239s 125ms/step - loss: -62455061454742976.0000\nEpoch 96/100\n1912/1912 [==============================] - 239s 125ms/step - loss: -63614478864055088.0000\nEpoch 97/100\n1912/1912 [==============================] - 237s 124ms/step - loss: -64778999961440344.0000\nEpoch 98/100\n1912/1912 [==============================] - 237s 124ms/step - loss: -65954434984047944.0000\nEpoch 99/100\n1912/1912 [==============================] - 235s 123ms/step - loss: -67138095349740264.0000\nEpoch 100/100\n1912/1912 [==============================] - 235s 123ms/step - loss: -68329416733060144.0000\nAutoencoder learning is over!\n"}],"source":["#オートエンコーダの定義\n","\n","from keras.models import Model\n","from keras.layers import Input, Dense\n","\n","def ae(input_dim,encode_dim):\n","\n","    input_data = Input(shape = (input_dim,))\n","    encoder = Dense(encode_dim,activation=\"relu\",kernel_initializer=\"he_normal\")(input_data)\n","    decoder = Dense(input_dim,activation=\"sigmoid\",kernel_initializer=\"he_normal\")(encoder)\n","    autoencoder = Model(input = input_data,output = decoder)\n","\n","    opt = keras.optimizers.nadam(lr = lr)\n","\n","    autoencoder.compile(optimizer = opt,loss='binary_crossentropy')\n","\n","    return autoencoder\n","\n","#オートエンコーダの学習\n","ae = ae(\n","    input_dim = X_train_ae.shape[1],\n","    encode_dim = encode_dim,\n",")\n","\n","ae.fit(\n","    X_train_ae,X_train_ae,\n","    epochs = epochs,\n","    batch_size = batch_size,\n","    shuffle = True\n",")\n","\n","print('Autoencoder learning is over!')\n",""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}