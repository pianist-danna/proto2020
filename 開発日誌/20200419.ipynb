{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Data loaded!!\n",
      "Training data amounts :3800\n",
      "Test data amounts :200\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Tensorflowによるオートエンコーダの実装\n",
    "思い出しがてらの作成なのでコメントが膨大…\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#%%\n",
    "# cording = UTF-8\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import copy\n",
    "import scipy\n",
    "import librosa #無くしたい\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import keras\n",
    "import tensorflow\n",
    "\n",
    "####################################初期化####################################\n",
    "aug_amount = 100    #ファイルごとのAugmentationの回数\n",
    "lr = 1e-01          #初期学習率\n",
    "alpha = 1e-03       #L2正則化の係数\n",
    "dr_rate = 0.3       #ドロップアウト率\n",
    "batch_size = 50\n",
    "epochs = 100\n",
    "encode_dim = 1000   #オートエンコーダの圧縮次元\n",
    "\n",
    "#ディレクトリの初期化\n",
    "base_dir = \"../\"\n",
    "data_dir =os.path.join(base_dir,\"data\")\n",
    "ok_dir = os.path.join(data_dir,\"OK\")\n",
    "ng_dir = os.path.join(data_dir,\"NG\")\n",
    "env_dir = os.path.join(data_dir,\"environment\")\n",
    "\n",
    "#学習用データファイル\n",
    "datafile = \"dataset2.npz\"\n",
    "\n",
    "####################################関数定義###################################\n",
    "\n",
    "#対象ディレクトリのファイル一覧を取得\n",
    "def get_file_list(dir):\n",
    "    path = dir\n",
    "    file_list = os.listdir(path)\n",
    "    print(\"get file_list :{}\".format(file_list))\n",
    "    return file_list\n",
    "\n",
    "#対象ディレクトリの最大ファイルをサーチ\n",
    "def wav_search(dir,f_list):\n",
    "    #呼び出されるごとに初期化する\n",
    "    wave_list = []\n",
    "    file_size = 0\n",
    "    \n",
    "    return_path = os.path.abspath('./')\n",
    "    \n",
    "    os.chdir(dir)\n",
    "    for i in f_list:\n",
    "        search_index = re.search('.wav',i)\n",
    "        if search_index:\n",
    "            wave_list .append(i)\n",
    "            if os.path.getsize(i) > file_size:\n",
    "                file_size = os.path.getsize(i)\n",
    "                largest_file = i\n",
    "        \n",
    "    os.chdir(return_path)   #カレントディレクトリを戻す\n",
    "    print(\"get file :{0} ,file size:{1}\"\\\n",
    "        .format(largest_file,file_size))\n",
    "    return wave_list,largest_file,file_size\n",
    "\n",
    "#オーディオファイルの読み込み サンプルレート22.05kHz、モノラルで固定\n",
    "def load_wav(dir,file):\n",
    "    #呼び出されるごとに初期化する\n",
    "    wf = np.arange(0)\n",
    "\n",
    "    f_path = os.path.join(dir,file)\n",
    "    wf,sp_rate = librosa.load(f_path,sr=22050,mono = True)\n",
    "    del sp_rate\n",
    "    return wf\n",
    "\n",
    "#スペクトログラムの取得 パワースペクトラムのまま処理するならlibrosa不要\n",
    "def get_spg(wf):\n",
    "    spg = np.arange(0)\n",
    "    sp_f,sp_t,spg = scipy.signal.spectrogram(wf,fs=22050,\n",
    "        window = np.hamming(1024),nfft =1024)\n",
    "    spg = librosa.power_to_db(spg)\n",
    "    spg =spg.astype('float16')\n",
    "    return sp_f,sp_t,spg\n",
    "\n",
    "#Augmentationの処理\n",
    "def aug_process(frame,dir,wave_list,env_file,):\n",
    "    #呼び出されるごとに初期化する\n",
    "    length = 0\n",
    "    count = 0\n",
    "    wf = np.arange(0)\n",
    "\n",
    "    length = int(frame * 1.2)\n",
    "    for i in wave_list:\n",
    "        wf = load_wav(dir,i)\n",
    "        for j in range(aug_amount):\n",
    "            start = random.randint(0,len(env_file)-length)\n",
    "            aug_wav = copy.deepcopy(env_file[start : start + length])\n",
    "            del start\n",
    "            start = random.randint(0,len(aug_wav) - len(wf))\n",
    "            aug_wav = aug_wav + random.gauss(1,0.05)\n",
    "            aug_wav[ start:start + len(wf) ] = \\\n",
    "                aug_wav[ start : start + len(wf) ] + wf\n",
    "            sp_f,sp_t,spg = get_spg(aug_wav)\n",
    "            spg = spg.reshape(1,len(sp_f),len(sp_t))\n",
    "            try:\n",
    "                X_data\n",
    "            except:\n",
    "                X_data = copy.deepcopy(spg)\n",
    "            else:\n",
    "                X_data = np.vstack((X_data,spg))\n",
    "            del start,aug_wav,sp_f,sp_t,spg\n",
    "            count = count + 1\n",
    "        del wf\n",
    "        print(\"Augmentation done! total count = {}\".format(count))\n",
    "\n",
    "    return X_data\n",
    "\n",
    "#データセットの作成 ここまでの関数は全部ここに集約される\n",
    "#最大ファイルサイズに合わせてフレームサイズを定義し\n",
    "#OK・NG各データセットを作成後、結合する\n",
    "\n",
    "def new_dataset(aug,ok_dir,ng_dir,env_dir):\n",
    "    #OKNGそれぞれのファイルリストと最大ファイルを取得\n",
    "    ok_filelist = get_file_list(ok_dir)\n",
    "    ok_wave_list,ok_largeest_name,ok_largest_size = wav_search(ok_dir,ok_filelist)\n",
    "    ng_filelist = get_file_list(ng_dir)\n",
    "    ng_wave_list,ng_largeest_name,ng_largest_size = wav_search(ng_dir,ng_filelist)\n",
    "\n",
    "    #OKNGの最大を比較\n",
    "    if ok_largest_size>ng_largest_size:\n",
    "        largest_dir = ok_dir\n",
    "        lergest_name = ok_largeest_name\n",
    "        print(\"largetst:OK\")\n",
    "    else:\n",
    "        largest_dir = ng_dir\n",
    "        lergest_name = ng_largeest_name\n",
    "        print(\"largetst:NG\")\n",
    "\n",
    "    #最大フレームサイズを取得\n",
    "    wf = load_wav(largest_dir,lergest_name)\n",
    "    frame = int(len(wf))\n",
    "    #wf = np.insert(wf,frame,np.empty(int(frame*0.2))) #1.2倍する\n",
    "    #sp_f,sp_t,spg = get_spg(wf) \n",
    "    #X_initsize = (len(sp_f),len(sp_t))\n",
    "    #del wf,sp_f,sp_t,spg\n",
    "    del wf\n",
    "\n",
    "    #環境音データをロード\n",
    "    env_data = load_wav(env_dir,\"env.wav\")\n",
    "    \n",
    "    #OKデータセット作成\n",
    "    X_ok = copy.deepcopy(\n",
    "        aug_process(frame,ok_dir,ok_wave_list,env_data)\n",
    "        )\n",
    "    y_ok = np.zeros(len(X_ok),dtype = 'bool')\n",
    "\n",
    "    #NGデータセット作成\n",
    "    X_ng = copy.deepcopy(\n",
    "        aug_process(frame,ng_dir,ng_wave_list,env_data)\n",
    "        )\n",
    "    y_ng = np.ones(len(X_ng),dtype = 'bool')\n",
    "\n",
    "    #データセットの結合\n",
    "    X_data = np.vstack((X_ok,X_ng))\n",
    "    y_data = np.append(y_ok,y_ng)\n",
    "    del X_ok,y_ok,X_ng,y_ng\n",
    "\n",
    "    return X_data,y_data\n",
    "\n",
    "#OKNGが混在したデータからFalseのみを分離する\n",
    "def mixed_to_sprit(X_mixed,y_mixed):\n",
    "    #呼び出されるごとに初期化する\n",
    "    try:\n",
    "        X_sprit\n",
    "    except:\n",
    "        pass    #X_spritが存在しなければ何もしない\n",
    "    else:\n",
    "        del X_sprit #前のデータを消去する\n",
    "\n",
    "    for i in range(len(X_mixed)):\n",
    "        if y_mixed[i] == False:\n",
    "            try:\n",
    "                X_sprit\n",
    "            except: #X_spritを生成する\n",
    "                X_sprit = copy.deepcopy(X_mixed[i])\n",
    "                X_sprit = X_sprit.reshape(1,X_mixed.shape[1])\n",
    "            else:   #既存のX_spritに追加する 前段の例外処理はここを避けるため\n",
    "                X_sprit = np.vstack(\n",
    "                    (X_sprit,X_mixed[i].reshape(1,X_mixed.shape[1]))\n",
    "                    )\n",
    "\n",
    "    return X_sprit\n",
    "\n",
    "###################################メイン処理###################################\n",
    "\n",
    "#データセット読み込み なければ作る\n",
    "if os.path.exists(os.path.join(data_dir,datafile)) == False:\n",
    "    X_data,y_data = new_dataset(aug_amount,ok_dir,ng_dir,env_dir)\n",
    "    np.savez_compressed(os.path.join(data_dir,datafile),\n",
    "        X = X_data,y = y_data)\n",
    "    print(\"Data set saved!\") #ファイルネーム表示機能つけること\n",
    "else:\n",
    "    load_data = np.load(os.path.join(data_dir,datafile))\n",
    "    X_data =load_data['X']\n",
    "    y_data = load_data['y']\n",
    "    del load_data\n",
    "    print(\"Data loaded!!\")\n",
    "\n",
    "#データ前処理 trainとtestを分離\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_shape = X_data.shape[1:]\n",
    "X_data = X_data.reshape(len(X_data),-1) #アフィン変換\n",
    "X_train,X_test,y_train,y_test = \\\n",
    "    train_test_split(X_data,y_data,test_size=0.05)\n",
    "print(\n",
    "\"Training data amounts :{0}\\n\\\n",
    "Test data amounts :{1}\"\\\n",
    ".format(len(y_train),len(y_test))\n",
    ")\n",
    "del X_data,y_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train for Autoencoder was splited!!\n",
      "amount/shape:(1905, 60021)\n"
     ]
    }
   ],
   "source": [
    "#X_trainからOKデータ(False)だけを抽出する\n",
    "\n",
    "X_train_ae = mixed_to_sprit(X_train,y_train)\n",
    "print(\n",
    "\"X_train for Autoencoder was splited!!\\n\\\n",
    "amount/shape:{0}\"\n",
    ".format(X_train_ae.shape)\n",
    ")\n",
    "\n",
    "#スケーラを定義する(AEの出力にシグモイドを使うため)\n",
    "scaler = sklearn.preprocessing.MinMaxScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#オートエンコーダの定義\n",
    "\n",
    "from keras.models import Model,Sequential\n",
    "from keras.layers import Input, Dense,Dropout,Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers\n",
    "\n",
    "#Modelでの実装 もう少しわかりやすい形にする\n",
    "def ae(input_dim,encode_dim,lr,alpha,dr_rate):\n",
    "\n",
    "    input_data = Input(shape = (input_dim,))\n",
    "\n",
    "    #エンコーダを定義\n",
    "    encoder = Dense(\n",
    "        encode_dim,\n",
    "        kernel_initializer=\"he_normal\",\n",
    "        kernel_regularizer=regularizers.l2(alpha),\n",
    "        )(input_data)\n",
    "    encoder = BatchNormalization()(encoder)\n",
    "    encoder = Dropout(dr_rate)(encoder)\n",
    "    encoder = Activation(\"relu\")(encoder)\n",
    "\n",
    "    #デコーダを定義 こっちにはドロップアウトは定義しない\n",
    "    decoder = Dense(input_dim,kernel_initializer=\"he_normal\")(encoder)\n",
    "    decoder = BatchNormalization()(decoder)\n",
    "    decoder = Activation(\"sigmoid\")(decoder)\n",
    "\n",
    "    #モデルを定義\n",
    "    autoencoder = Model(input = input_data,output = decoder)\n",
    "\n",
    "    #最適化関数 Nadamをデフォルトパラメタで使う\n",
    "    opt = keras.optimizers.nadam(lr = lr)\n",
    "\n",
    "    autoencoder.compile(\n",
    "        optimizer = opt,loss='binary_crossentropy',metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "    return autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- loss: 0.7124 - accuracy: 0.0331\n",
      "Epoch 9/10\n",
      "1270/1270 [==============================] - 67s 53ms/step - loss: 0.7130 - accuracy: 0.0331\n",
      "Epoch 10/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.7138 - accuracy: 0.0331\n",
      "635/635 [==============================] - 4s 6ms/step\n",
      "1270/1270 [==============================] - 9s 7ms/step\n",
      "[CV]  alpha=0.0001, batch_size=50, dr_rate=0.2, epochs=10, lr=0.01, total=11.5min\n",
      "[CV] alpha=0.0001, batch_size=50, dr_rate=0.2, epochs=10, lr=0.01 ....\n",
      "Epoch 1/10\n",
      "1270/1270 [==============================] - 69s 54ms/step - loss: 0.8276 - accuracy: 0.0212\n",
      "Epoch 2/10\n",
      "1270/1270 [==============================] - 67s 53ms/step - loss: 0.7802 - accuracy: 0.0261\n",
      "Epoch 3/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.7462 - accuracy: 0.0313\n",
      "Epoch 4/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.7344 - accuracy: 0.0331\n",
      "Epoch 5/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.7262 - accuracy: 0.0334\n",
      "Epoch 6/10\n",
      "1270/1270 [==============================] - 67s 53ms/step - loss: 0.7143 - accuracy: 0.0334\n",
      "Epoch 7/10\n",
      "1270/1270 [==============================] - 70s 55ms/step - loss: 0.7132 - accuracy: 0.0334\n",
      "Epoch 8/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.7153 - accuracy: 0.0334\n",
      "Epoch 9/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.7098 - accuracy: 0.0334\n",
      "Epoch 10/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.7205 - accuracy: 0.0333\n",
      "635/635 [==============================] - 4s 6ms/step\n",
      "1270/1270 [==============================] - 7s 6ms/step\n",
      "[CV]  alpha=0.0001, batch_size=50, dr_rate=0.2, epochs=10, lr=0.01, total=11.5min\n",
      "[CV] alpha=0.0001, batch_size=50, dr_rate=0.2, epochs=10, lr=0.01 ....\n",
      "Epoch 1/10\n",
      "1270/1270 [==============================] - 69s 54ms/step - loss: 0.8458 - accuracy: 0.0214\n",
      "Epoch 2/10\n",
      "1270/1270 [==============================] - 70s 55ms/step - loss: 0.7735 - accuracy: 0.0263\n",
      "Epoch 3/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.7471 - accuracy: 0.0315\n",
      "Epoch 4/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.7251 - accuracy: 0.0332\n",
      "Epoch 5/10\n",
      "1270/1270 [==============================] - 67s 53ms/step - loss: 0.7336 - accuracy: 0.0334\n",
      "Epoch 6/10\n",
      "1270/1270 [==============================] - 67s 53ms/step - loss: 0.7255 - accuracy: 0.0334\n",
      "Epoch 7/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.7150 - accuracy: 0.0334\n",
      "Epoch 8/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.7125 - accuracy: 0.0333\n",
      "Epoch 9/10\n",
      "1270/1270 [==============================] - 71s 56ms/step - loss: 0.7102 - accuracy: 0.0334\n",
      "Epoch 10/10\n",
      "1270/1270 [==============================] - 69s 54ms/step - loss: 0.7128 - accuracy: 0.0334\n",
      "635/635 [==============================] - 4s 6ms/step\n",
      "1270/1270 [==============================] - 8s 6ms/step\n",
      "[CV]  alpha=0.0001, batch_size=50, dr_rate=0.2, epochs=10, lr=0.01, total=11.6min\n",
      "[CV] alpha=1e-05, batch_size=50, dr_rate=0.2, epochs=10, lr=0.1 ......\n",
      "Epoch 1/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 1.0232 - accuracy: 0.0296\n",
      "Epoch 2/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.8212 - accuracy: 0.0313\n",
      "Epoch 3/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.8924 - accuracy: 0.0311\n",
      "Epoch 4/10\n",
      "1270/1270 [==============================] - 69s 55ms/step - loss: 0.9258 - accuracy: 0.0311\n",
      "Epoch 5/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.9324 - accuracy: 0.0312\n",
      "Epoch 6/10\n",
      "1270/1270 [==============================] - 67s 53ms/step - loss: 0.9463 - accuracy: 0.0312\n",
      "Epoch 7/10\n",
      "1270/1270 [==============================] - 67s 53ms/step - loss: 0.9559 - accuracy: 0.0313\n",
      "Epoch 8/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.9425 - accuracy: 0.0314\n",
      "Epoch 9/10\n",
      "1270/1270 [==============================] - 67s 53ms/step - loss: 0.9436 - accuracy: 0.0314\n",
      "Epoch 10/10\n",
      "1270/1270 [==============================] - 67s 53ms/step - loss: 0.9464 - accuracy: 0.0314\n",
      "635/635 [==============================] - 4s 6ms/step\n",
      "1270/1270 [==============================] - 10s 8ms/step\n",
      "[CV]  alpha=1e-05, batch_size=50, dr_rate=0.2, epochs=10, lr=0.1, total=11.5min\n",
      "[CV] alpha=1e-05, batch_size=50, dr_rate=0.2, epochs=10, lr=0.1 ......\n",
      "Epoch 1/10\n",
      "1270/1270 [==============================] - 79s 62ms/step - loss: 1.2825 - accuracy: 0.0305\n",
      "Epoch 2/10\n",
      "1270/1270 [==============================] - 69s 54ms/step - loss: 0.7730 - accuracy: 0.0327\n",
      "Epoch 3/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.8336 - accuracy: 0.0329\n",
      "Epoch 4/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.8631 - accuracy: 0.0329\n",
      "Epoch 5/10\n",
      "1270/1270 [==============================] - 70s 55ms/step - loss: 0.8972 - accuracy: 0.0329\n",
      "Epoch 6/10\n",
      "1270/1270 [==============================] - 69s 54ms/step - loss: 0.9259 - accuracy: 0.0330\n",
      "Epoch 7/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.9317 - accuracy: 0.0330\n",
      "Epoch 8/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.9497 - accuracy: 0.0330\n",
      "Epoch 9/10\n",
      "1270/1270 [==============================] - 69s 54ms/step - loss: 0.9488 - accuracy: 0.0330\n",
      "Epoch 10/10\n",
      "1270/1270 [==============================] - 69s 54ms/step - loss: 0.9397 - accuracy: 0.0330\n",
      "635/635 [==============================] - 7s 11ms/step\n",
      "1270/1270 [==============================] - 10s 8ms/step\n",
      "[CV]  alpha=1e-05, batch_size=50, dr_rate=0.2, epochs=10, lr=0.1, total=11.8min\n",
      "[CV] alpha=1e-05, batch_size=50, dr_rate=0.2, epochs=10, lr=0.1 ......\n",
      "Epoch 1/10\n",
      "1270/1270 [==============================] - 69s 54ms/step - loss: 1.2445 - accuracy: 0.0301\n",
      "Epoch 2/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.7373 - accuracy: 0.0313\n",
      "Epoch 3/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.8568 - accuracy: 0.0314\n",
      "Epoch 4/10\n",
      "1270/1270 [==============================] - 69s 54ms/step - loss: 0.8985 - accuracy: 0.0313\n",
      "Epoch 5/10\n",
      "1270/1270 [==============================] - 71s 56ms/step - loss: 0.9161 - accuracy: 0.0314\n",
      "Epoch 6/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.9351 - accuracy: 0.0313\n",
      "Epoch 7/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.9426 - accuracy: 0.0314\n",
      "Epoch 8/10\n",
      "1270/1270 [==============================] - 69s 54ms/step - loss: 0.9387 - accuracy: 0.0314\n",
      "Epoch 9/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.9420 - accuracy: 0.0315\n",
      "Epoch 10/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.9456 - accuracy: 0.0314\n",
      "635/635 [==============================] - 4s 6ms/step\n",
      "1270/1270 [==============================] - 10s 8ms/step\n",
      "[CV]  alpha=1e-05, batch_size=50, dr_rate=0.2, epochs=10, lr=0.1, total=11.8min\n",
      "[CV] alpha=1e-05, batch_size=50, dr_rate=0.2, epochs=10, lr=0.05 .....\n",
      "Epoch 1/10\n",
      "1270/1270 [==============================] - 69s 54ms/step - loss: 0.8305 - accuracy: 0.0277\n",
      "Epoch 2/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.7069 - accuracy: 0.0329\n",
      "Epoch 3/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.7125 - accuracy: 0.0329\n",
      "Epoch 4/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.7062 - accuracy: 0.0330\n",
      "Epoch 5/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.7086 - accuracy: 0.0330\n",
      "Epoch 6/10\n",
      "1270/1270 [==============================] - 69s 55ms/step - loss: 0.7079 - accuracy: 0.0330\n",
      "Epoch 7/10\n",
      "1270/1270 [==============================] - 69s 54ms/step - loss: 0.7043 - accuracy: 0.0330\n",
      "Epoch 8/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.7101 - accuracy: 0.0331\n",
      "Epoch 9/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.7063 - accuracy: 0.0330\n",
      "Epoch 10/10\n",
      "1270/1270 [==============================] - 69s 54ms/step - loss: 0.7072 - accuracy: 0.0331\n",
      "635/635 [==============================] - 4s 6ms/step\n",
      "1270/1270 [==============================] - 7s 6ms/step\n",
      "[CV]  alpha=1e-05, batch_size=50, dr_rate=0.2, epochs=10, lr=0.05, total=11.5min\n",
      "[CV] alpha=1e-05, batch_size=50, dr_rate=0.2, epochs=10, lr=0.05 .....\n",
      "Epoch 1/10\n",
      "1270/1270 [==============================] - 71s 56ms/step - loss: 0.8334 - accuracy: 0.0279\n",
      "Epoch 2/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.7056 - accuracy: 0.0331\n",
      "Epoch 3/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.7099 - accuracy: 0.0332\n",
      "Epoch 4/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.7115 - accuracy: 0.0332\n",
      "Epoch 5/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.7111 - accuracy: 0.0332\n",
      "Epoch 6/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.7092 - accuracy: 0.0333\n",
      "Epoch 7/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.7065 - accuracy: 0.0333\n",
      "Epoch 8/10\n",
      "1270/1270 [==============================] - 70s 55ms/step - loss: 0.7086 - accuracy: 0.0333\n",
      "Epoch 9/10\n",
      "1270/1270 [==============================] - 69s 54ms/step - loss: 0.7055 - accuracy: 0.0333\n",
      "Epoch 10/10\n",
      "1270/1270 [==============================] - 70s 55ms/step - loss: 0.7040 - accuracy: 0.0333\n",
      "635/635 [==============================] - 4s 6ms/step\n",
      "1270/1270 [==============================] - 8s 6ms/step\n",
      "[CV]  alpha=1e-05, batch_size=50, dr_rate=0.2, epochs=10, lr=0.05, total=11.6min\n",
      "[CV] alpha=1e-05, batch_size=50, dr_rate=0.2, epochs=10, lr=0.05 .....\n",
      "Epoch 1/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.8971 - accuracy: 0.0285\n",
      "Epoch 2/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.7013 - accuracy: 0.0332\n",
      "Epoch 3/10\n",
      "1270/1270 [==============================] - 70s 55ms/step - loss: 0.7106 - accuracy: 0.0331\n",
      "Epoch 4/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.7185 - accuracy: 0.0331\n",
      "Epoch 5/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.7029 - accuracy: 0.0332\n",
      "Epoch 6/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.7070 - accuracy: 0.0332\n",
      "Epoch 7/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.7038 - accuracy: 0.0332\n",
      "Epoch 8/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.7083 - accuracy: 0.0332\n",
      "Epoch 9/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.7060 - accuracy: 0.0332\n",
      "Epoch 10/10\n",
      "1270/1270 [==============================] - 69s 54ms/step - loss: 0.7095 - accuracy: 0.0333\n",
      "635/635 [==============================] - 4s 6ms/step\n",
      "1270/1270 [==============================] - 7s 6ms/step\n",
      "[CV]  alpha=1e-05, batch_size=50, dr_rate=0.2, epochs=10, lr=0.05, total=11.5min\n",
      "[CV] alpha=1e-05, batch_size=50, dr_rate=0.2, epochs=10, lr=0.025 ....\n",
      "Epoch 1/10\n",
      "1270/1270 [==============================] - 69s 54ms/step - loss: 0.7708 - accuracy: 0.0244\n",
      "Epoch 2/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.6826 - accuracy: 0.0328\n",
      "Epoch 3/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.6738 - accuracy: 0.0333\n",
      "Epoch 4/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.6729 - accuracy: 0.0332\n",
      "Epoch 5/10\n",
      "1270/1270 [==============================] - 70s 55ms/step - loss: 0.6752 - accuracy: 0.0333\n",
      "Epoch 6/10\n",
      "1270/1270 [==============================] - 69s 54ms/step - loss: 0.6760 - accuracy: 0.0333\n",
      "Epoch 7/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.6750 - accuracy: 0.0333\n",
      "Epoch 8/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.6783 - accuracy: 0.0333\n",
      "Epoch 9/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.6775 - accuracy: 0.0333\n",
      "Epoch 10/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.6781 - accuracy: 0.0333\n",
      "635/635 [==============================] - 4s 6ms/step\n",
      "1270/1270 [==============================] - 10s 8ms/step\n",
      "[CV]  alpha=1e-05, batch_size=50, dr_rate=0.2, epochs=10, lr=0.025, total=11.5min\n",
      "[CV] alpha=1e-05, batch_size=50, dr_rate=0.2, epochs=10, lr=0.025 ....\n",
      "Epoch 1/10\n",
      "1270/1270 [==============================] - 70s 55ms/step - loss: 0.7712 - accuracy: 0.0242\n",
      "Epoch 2/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.6827 - accuracy: 0.0331\n",
      "Epoch 3/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.6721 - accuracy: 0.0335\n",
      "Epoch 4/10\n",
      "1270/1270 [==============================] - 67s 53ms/step - loss: 0.6727 - accuracy: 0.0335\n",
      "Epoch 5/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.6746 - accuracy: 0.0335\n",
      "Epoch 6/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.6750 - accuracy: 0.0335\n",
      "Epoch 7/10\n",
      "1270/1270 [==============================] - 70s 55ms/step - loss: 0.6785 - accuracy: 0.0335\n",
      "Epoch 8/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.6785 - accuracy: 0.0335\n",
      "Epoch 9/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.6773 - accuracy: 0.0335\n",
      "Epoch 10/10\n",
      "1270/1270 [==============================] - 67s 53ms/step - loss: 0.6779 - accuracy: 0.0335\n",
      "635/635 [==============================] - 4s 6ms/step\n",
      "1270/1270 [==============================] - 9s 7ms/step\n",
      "[CV]  alpha=1e-05, batch_size=50, dr_rate=0.2, epochs=10, lr=0.025, total=11.5min\n",
      "[CV] alpha=1e-05, batch_size=50, dr_rate=0.2, epochs=10, lr=0.025 ....\n",
      "Epoch 1/10\n",
      "1270/1270 [==============================] - 71s 56ms/step - loss: 0.7698 - accuracy: 0.0242\n",
      "Epoch 2/10\n",
      "1270/1270 [==============================] - 69s 55ms/step - loss: 0.6827 - accuracy: 0.0330\n",
      "Epoch 3/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.6740 - accuracy: 0.0335\n",
      "Epoch 4/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.6741 - accuracy: 0.0335\n",
      "Epoch 5/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.6759 - accuracy: 0.0335\n",
      "Epoch 6/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.6765 - accuracy: 0.0335\n",
      "Epoch 7/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.6772 - accuracy: 0.0335\n",
      "Epoch 8/10\n",
      "1270/1270 [==============================] - 69s 54ms/step - loss: 0.6772 - accuracy: 0.0335\n",
      "Epoch 9/10\n",
      "1270/1270 [==============================] - 70s 55ms/step - loss: 0.6799 - accuracy: 0.0335\n",
      "Epoch 10/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.6807 - accuracy: 0.0335\n",
      "635/635 [==============================] - 4s 6ms/step\n",
      "1270/1270 [==============================] - 7s 6ms/step\n",
      "[CV]  alpha=1e-05, batch_size=50, dr_rate=0.2, epochs=10, lr=0.025, total=11.6min\n",
      "[CV] alpha=1e-05, batch_size=50, dr_rate=0.2, epochs=10, lr=0.01 .....\n",
      "Epoch 1/10\n",
      "1270/1270 [==============================] - 69s 54ms/step - loss: 0.7592 - accuracy: 0.0222\n",
      "Epoch 2/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.6936 - accuracy: 0.0274\n",
      "Epoch 3/10\n",
      "1270/1270 [==============================] - 69s 55ms/step - loss: 0.6741 - accuracy: 0.0318\n",
      "Epoch 4/10\n",
      "1270/1270 [==============================] - 69s 54ms/step - loss: 0.6656 - accuracy: 0.0332\n",
      "Epoch 5/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.6616 - accuracy: 0.0335\n",
      "Epoch 6/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.6597 - accuracy: 0.0335\n",
      "Epoch 7/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.6588 - accuracy: 0.0335\n",
      "Epoch 8/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.6577 - accuracy: 0.0335\n",
      "Epoch 9/10\n",
      "1270/1270 [==============================] - 68s 53ms/step - loss: 0.6578 - accuracy: 0.0335\n",
      "Epoch 10/10\n",
      "1270/1270 [==============================] - 69s 54ms/step - loss: 0.6572 - accuracy: 0.0335\n",
      "635/635 [==============================] - 6s 9ms/step\n",
      "1270/1270 [==============================] - 8s 6ms/step\n",
      "[CV]  alpha=1e-05, batch_size=50, dr_rate=0.2, epochs=10, lr=0.01, total=11.6min\n",
      "[CV] alpha=1e-05, batch_size=50, dr_rate=0.2, epochs=10, lr=0.01 .....\n",
      "Epoch 1/10\n",
      "1270/1270 [==============================] - 71s 56ms/step - loss: 0.7505 - accuracy: 0.0223\n",
      "Epoch 2/10\n",
      "1270/1270 [==============================] - 69s 54ms/step - loss: 0.6947 - accuracy: 0.0274\n",
      "Epoch 3/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.6754 - accuracy: 0.0319\n",
      "Epoch 4/10\n",
      "1270/1270 [==============================] - 69s 55ms/step - loss: 0.6661 - accuracy: 0.0334\n",
      "Epoch 5/10\n",
      "1270/1270 [==============================] - 71s 56ms/step - loss: 0.6617 - accuracy: 0.0337\n",
      "Epoch 6/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.6598 - accuracy: 0.0337\n",
      "Epoch 7/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.6588 - accuracy: 0.0337\n",
      "Epoch 8/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.6576 - accuracy: 0.0338\n",
      "Epoch 9/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.6581 - accuracy: 0.0338\n",
      "Epoch 10/10\n",
      "1270/1270 [==============================] - 69s 54ms/step - loss: 0.6575 - accuracy: 0.0338\n",
      "635/635 [==============================] - 4s 7ms/step\n",
      "1270/1270 [==============================] - 10s 8ms/step\n",
      "[CV]  alpha=1e-05, batch_size=50, dr_rate=0.2, epochs=10, lr=0.01, total=11.7min\n",
      "[CV] alpha=1e-05, batch_size=50, dr_rate=0.2, epochs=10, lr=0.01 .....\n",
      "Epoch 1/10\n",
      "1270/1270 [==============================] - 69s 55ms/step - loss: 0.7506 - accuracy: 0.0225\n",
      "Epoch 2/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.6940 - accuracy: 0.0280\n",
      "Epoch 3/10\n",
      "1270/1270 [==============================] - 69s 54ms/step - loss: 0.6749 - accuracy: 0.0321\n",
      "Epoch 4/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.6660 - accuracy: 0.0334\n",
      "Epoch 5/10\n",
      "1270/1270 [==============================] - 69s 54ms/step - loss: 0.6615 - accuracy: 0.0337\n",
      "Epoch 6/10\n",
      "1270/1270 [==============================] - 71s 56ms/step - loss: 0.6594 - accuracy: 0.0337\n",
      "Epoch 7/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.6586 - accuracy: 0.0337\n",
      "Epoch 8/10\n",
      "1270/1270 [==============================] - 68s 54ms/step - loss: 0.6577 - accuracy: 0.0338\n",
      "Epoch 9/10\n",
      "1270/1270 [==============================] - 69s 55ms/step - loss: 0.6586 - accuracy: 0.0338\n",
      "Epoch 10/10\n",
      "1270/1270 [==============================] - 69s 54ms/step - loss: 0.6574 - accuracy: 0.0338\n",
      "635/635 [==============================] - 4s 6ms/step\n",
      "1270/1270 [==============================] - 9s 7ms/step\n",
      "[CV]  alpha=1e-05, batch_size=50, dr_rate=0.2, epochs=10, lr=0.01, total=11.6min\n",
      "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed: 559.7min finished\n",
      "Epoch 1/10\n",
      "1905/1905 [==============================] - 103s 54ms/step - loss: 1.7915 - accuracy: 0.0277\n",
      "Epoch 2/10\n",
      "1905/1905 [==============================] - 104s 54ms/step - loss: 1.7487 - accuracy: 0.0315\n",
      "Epoch 3/10\n",
      "1905/1905 [==============================] - 104s 55ms/step - loss: 1.7500 - accuracy: 0.0315\n",
      "Epoch 4/10\n",
      "1905/1905 [==============================] - 102s 54ms/step - loss: 1.7292 - accuracy: 0.0315\n",
      "Epoch 5/10\n",
      "1905/1905 [==============================] - 104s 54ms/step - loss: 1.7036 - accuracy: 0.0316\n",
      "Epoch 6/10\n",
      "1905/1905 [==============================] - 105s 55ms/step - loss: 1.7105 - accuracy: 0.0316\n",
      "Epoch 7/10\n",
      "1905/1905 [==============================] - 104s 54ms/step - loss: 1.6704 - accuracy: 0.0317\n",
      "Epoch 8/10\n",
      "1905/1905 [==============================] - 101s 53ms/step - loss: 1.6647 - accuracy: 0.0317\n",
      "Epoch 9/10\n",
      "1905/1905 [==============================] - 104s 54ms/step - loss: 1.6429 - accuracy: 0.0317\n",
      "Epoch 10/10\n",
      "1905/1905 [==============================] - 103s 54ms/step - loss: 1.6302 - accuracy: 0.0317\n",
      "Gridsearch is over!\n",
      "Best parameters :{'alpha': 0.0001, 'batch_size': 50, 'dr_rate': 0.2, 'epochs': 10, 'lr': 0.05}\n",
      "Best cross-validation score :0.6326292157173157\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_batch_size</th>\n",
       "      <th>param_dr_rate</th>\n",
       "      <th>param_epochs</th>\n",
       "      <th>param_lr</th>\n",
       "      <th>params</th>\n",
       "      <th>...</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>676.709715</td>\n",
       "      <td>1.284219</td>\n",
       "      <td>4.880556</td>\n",
       "      <td>0.035856</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.01, 'batch_size': 50, 'dr_rate': 0...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216532</td>\n",
       "      <td>0.259065</td>\n",
       "      <td>0.251375</td>\n",
       "      <td>0.025887</td>\n",
       "      <td>16</td>\n",
       "      <td>0.278121</td>\n",
       "      <td>0.217265</td>\n",
       "      <td>0.259884</td>\n",
       "      <td>0.251757</td>\n",
       "      <td>0.025500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>679.371769</td>\n",
       "      <td>0.287220</td>\n",
       "      <td>4.910863</td>\n",
       "      <td>0.015328</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'alpha': 0.01, 'batch_size': 50, 'dr_rate': 0...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.460712</td>\n",
       "      <td>0.513429</td>\n",
       "      <td>0.525485</td>\n",
       "      <td>0.058435</td>\n",
       "      <td>9</td>\n",
       "      <td>0.601711</td>\n",
       "      <td>0.461010</td>\n",
       "      <td>0.514090</td>\n",
       "      <td>0.525604</td>\n",
       "      <td>0.058015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>680.095711</td>\n",
       "      <td>0.426764</td>\n",
       "      <td>5.384297</td>\n",
       "      <td>0.684221</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.025</td>\n",
       "      <td>{'alpha': 0.01, 'batch_size': 50, 'dr_rate': 0...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353240</td>\n",
       "      <td>0.506078</td>\n",
       "      <td>0.426300</td>\n",
       "      <td>0.062576</td>\n",
       "      <td>13</td>\n",
       "      <td>0.418713</td>\n",
       "      <td>0.353548</td>\n",
       "      <td>0.506415</td>\n",
       "      <td>0.426225</td>\n",
       "      <td>0.062633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>675.790591</td>\n",
       "      <td>3.418472</td>\n",
       "      <td>4.973040</td>\n",
       "      <td>0.131345</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.01, 'batch_size': 50, 'dr_rate': 0...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.465322</td>\n",
       "      <td>0.838214</td>\n",
       "      <td>0.581501</td>\n",
       "      <td>0.181795</td>\n",
       "      <td>6</td>\n",
       "      <td>0.440532</td>\n",
       "      <td>0.465411</td>\n",
       "      <td>0.838661</td>\n",
       "      <td>0.581535</td>\n",
       "      <td>0.182099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>677.806348</td>\n",
       "      <td>4.874910</td>\n",
       "      <td>4.894068</td>\n",
       "      <td>0.018355</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.001, 'batch_size': 50, 'dr_rate': ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325556</td>\n",
       "      <td>0.417745</td>\n",
       "      <td>0.373630</td>\n",
       "      <td>0.037740</td>\n",
       "      <td>15</td>\n",
       "      <td>0.377746</td>\n",
       "      <td>0.325896</td>\n",
       "      <td>0.418839</td>\n",
       "      <td>0.374160</td>\n",
       "      <td>0.038029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>682.772089</td>\n",
       "      <td>3.044861</td>\n",
       "      <td>4.925669</td>\n",
       "      <td>0.062622</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'alpha': 0.001, 'batch_size': 50, 'dr_rate': ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375811</td>\n",
       "      <td>0.428267</td>\n",
       "      <td>0.391008</td>\n",
       "      <td>0.026495</td>\n",
       "      <td>14</td>\n",
       "      <td>0.368546</td>\n",
       "      <td>0.376059</td>\n",
       "      <td>0.428220</td>\n",
       "      <td>0.390942</td>\n",
       "      <td>0.026538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>686.003868</td>\n",
       "      <td>3.181157</td>\n",
       "      <td>4.912249</td>\n",
       "      <td>0.077953</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.025</td>\n",
       "      <td>{'alpha': 0.001, 'batch_size': 50, 'dr_rate': ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.439983</td>\n",
       "      <td>0.686201</td>\n",
       "      <td>0.585891</td>\n",
       "      <td>0.105563</td>\n",
       "      <td>5</td>\n",
       "      <td>0.630931</td>\n",
       "      <td>0.440430</td>\n",
       "      <td>0.686590</td>\n",
       "      <td>0.585984</td>\n",
       "      <td>0.105401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>681.243832</td>\n",
       "      <td>1.472526</td>\n",
       "      <td>5.334801</td>\n",
       "      <td>0.496651</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.001, 'batch_size': 50, 'dr_rate': ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512216</td>\n",
       "      <td>0.402893</td>\n",
       "      <td>0.489728</td>\n",
       "      <td>0.063736</td>\n",
       "      <td>12</td>\n",
       "      <td>0.554464</td>\n",
       "      <td>0.511867</td>\n",
       "      <td>0.402699</td>\n",
       "      <td>0.489677</td>\n",
       "      <td>0.063914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>682.712730</td>\n",
       "      <td>2.984906</td>\n",
       "      <td>5.459434</td>\n",
       "      <td>0.667312</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.0001, 'batch_size': 50, 'dr_rate':...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456207</td>\n",
       "      <td>0.619205</td>\n",
       "      <td>0.510466</td>\n",
       "      <td>0.076890</td>\n",
       "      <td>11</td>\n",
       "      <td>0.456282</td>\n",
       "      <td>0.455923</td>\n",
       "      <td>0.619940</td>\n",
       "      <td>0.510715</td>\n",
       "      <td>0.077234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>684.780504</td>\n",
       "      <td>2.700059</td>\n",
       "      <td>6.066614</td>\n",
       "      <td>1.570684</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'alpha': 0.0001, 'batch_size': 50, 'dr_rate':...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.614791</td>\n",
       "      <td>0.573849</td>\n",
       "      <td>0.632629</td>\n",
       "      <td>0.056697</td>\n",
       "      <td>1</td>\n",
       "      <td>0.708483</td>\n",
       "      <td>0.614910</td>\n",
       "      <td>0.574878</td>\n",
       "      <td>0.632757</td>\n",
       "      <td>0.055985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>687.834276</td>\n",
       "      <td>1.929265</td>\n",
       "      <td>5.093058</td>\n",
       "      <td>0.102747</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.025</td>\n",
       "      <td>{'alpha': 0.0001, 'batch_size': 50, 'dr_rate':...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.471786</td>\n",
       "      <td>0.580553</td>\n",
       "      <td>0.531478</td>\n",
       "      <td>0.045034</td>\n",
       "      <td>8</td>\n",
       "      <td>0.542517</td>\n",
       "      <td>0.471699</td>\n",
       "      <td>0.582153</td>\n",
       "      <td>0.532123</td>\n",
       "      <td>0.045688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>686.194024</td>\n",
       "      <td>2.134440</td>\n",
       "      <td>4.973192</td>\n",
       "      <td>0.040478</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.0001, 'batch_size': 50, 'dr_rate':...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512499</td>\n",
       "      <td>0.447500</td>\n",
       "      <td>0.590082</td>\n",
       "      <td>0.157925</td>\n",
       "      <td>3</td>\n",
       "      <td>0.810570</td>\n",
       "      <td>0.512502</td>\n",
       "      <td>0.446830</td>\n",
       "      <td>0.589967</td>\n",
       "      <td>0.158277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>694.594347</td>\n",
       "      <td>8.770523</td>\n",
       "      <td>6.583649</td>\n",
       "      <td>2.099640</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 1e-05, 'batch_size': 50, 'dr_rate': ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388880</td>\n",
       "      <td>0.506881</td>\n",
       "      <td>0.589210</td>\n",
       "      <td>0.205593</td>\n",
       "      <td>4</td>\n",
       "      <td>0.871917</td>\n",
       "      <td>0.388714</td>\n",
       "      <td>0.507388</td>\n",
       "      <td>0.589340</td>\n",
       "      <td>0.205602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>688.436281</td>\n",
       "      <td>1.738095</td>\n",
       "      <td>5.358524</td>\n",
       "      <td>0.308141</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'alpha': 1e-05, 'batch_size': 50, 'dr_rate': ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345730</td>\n",
       "      <td>0.506573</td>\n",
       "      <td>0.522480</td>\n",
       "      <td>0.151229</td>\n",
       "      <td>10</td>\n",
       "      <td>0.715316</td>\n",
       "      <td>0.345507</td>\n",
       "      <td>0.505521</td>\n",
       "      <td>0.522115</td>\n",
       "      <td>0.151429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>687.606831</td>\n",
       "      <td>2.168695</td>\n",
       "      <td>5.186149</td>\n",
       "      <td>0.240429</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.025</td>\n",
       "      <td>{'alpha': 1e-05, 'batch_size': 50, 'dr_rate': ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.586399</td>\n",
       "      <td>0.532717</td>\n",
       "      <td>0.559137</td>\n",
       "      <td>0.021924</td>\n",
       "      <td>7</td>\n",
       "      <td>0.559606</td>\n",
       "      <td>0.586277</td>\n",
       "      <td>0.532203</td>\n",
       "      <td>0.559362</td>\n",
       "      <td>0.022077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>691.885679</td>\n",
       "      <td>3.461256</td>\n",
       "      <td>5.934309</td>\n",
       "      <td>0.893186</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 1e-05, 'batch_size': 50, 'dr_rate': ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617422</td>\n",
       "      <td>0.608839</td>\n",
       "      <td>0.599471</td>\n",
       "      <td>0.019632</td>\n",
       "      <td>2</td>\n",
       "      <td>0.572908</td>\n",
       "      <td>0.616805</td>\n",
       "      <td>0.607930</td>\n",
       "      <td>0.599214</td>\n",
       "      <td>0.018951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0      676.709715      1.284219         4.880556        0.035856        0.01   \n",
       "1      679.371769      0.287220         4.910863        0.015328        0.01   \n",
       "2      680.095711      0.426764         5.384297        0.684221        0.01   \n",
       "3      675.790591      3.418472         4.973040        0.131345        0.01   \n",
       "4      677.806348      4.874910         4.894068        0.018355       0.001   \n",
       "5      682.772089      3.044861         4.925669        0.062622       0.001   \n",
       "6      686.003868      3.181157         4.912249        0.077953       0.001   \n",
       "7      681.243832      1.472526         5.334801        0.496651       0.001   \n",
       "8      682.712730      2.984906         5.459434        0.667312      0.0001   \n",
       "9      684.780504      2.700059         6.066614        1.570684      0.0001   \n",
       "10     687.834276      1.929265         5.093058        0.102747      0.0001   \n",
       "11     686.194024      2.134440         4.973192        0.040478      0.0001   \n",
       "12     694.594347      8.770523         6.583649        2.099640       1e-05   \n",
       "13     688.436281      1.738095         5.358524        0.308141       1e-05   \n",
       "14     687.606831      2.168695         5.186149        0.240429       1e-05   \n",
       "15     691.885679      3.461256         5.934309        0.893186       1e-05   \n",
       "\n",
       "   param_batch_size param_dr_rate param_epochs param_lr  \\\n",
       "0                50           0.2           10      0.1   \n",
       "1                50           0.2           10     0.05   \n",
       "2                50           0.2           10    0.025   \n",
       "3                50           0.2           10     0.01   \n",
       "4                50           0.2           10      0.1   \n",
       "5                50           0.2           10     0.05   \n",
       "6                50           0.2           10    0.025   \n",
       "7                50           0.2           10     0.01   \n",
       "8                50           0.2           10      0.1   \n",
       "9                50           0.2           10     0.05   \n",
       "10               50           0.2           10    0.025   \n",
       "11               50           0.2           10     0.01   \n",
       "12               50           0.2           10      0.1   \n",
       "13               50           0.2           10     0.05   \n",
       "14               50           0.2           10    0.025   \n",
       "15               50           0.2           10     0.01   \n",
       "\n",
       "                                               params  ...  split1_test_score  \\\n",
       "0   {'alpha': 0.01, 'batch_size': 50, 'dr_rate': 0...  ...           0.216532   \n",
       "1   {'alpha': 0.01, 'batch_size': 50, 'dr_rate': 0...  ...           0.460712   \n",
       "2   {'alpha': 0.01, 'batch_size': 50, 'dr_rate': 0...  ...           0.353240   \n",
       "3   {'alpha': 0.01, 'batch_size': 50, 'dr_rate': 0...  ...           0.465322   \n",
       "4   {'alpha': 0.001, 'batch_size': 50, 'dr_rate': ...  ...           0.325556   \n",
       "5   {'alpha': 0.001, 'batch_size': 50, 'dr_rate': ...  ...           0.375811   \n",
       "6   {'alpha': 0.001, 'batch_size': 50, 'dr_rate': ...  ...           0.439983   \n",
       "7   {'alpha': 0.001, 'batch_size': 50, 'dr_rate': ...  ...           0.512216   \n",
       "8   {'alpha': 0.0001, 'batch_size': 50, 'dr_rate':...  ...           0.456207   \n",
       "9   {'alpha': 0.0001, 'batch_size': 50, 'dr_rate':...  ...           0.614791   \n",
       "10  {'alpha': 0.0001, 'batch_size': 50, 'dr_rate':...  ...           0.471786   \n",
       "11  {'alpha': 0.0001, 'batch_size': 50, 'dr_rate':...  ...           0.512499   \n",
       "12  {'alpha': 1e-05, 'batch_size': 50, 'dr_rate': ...  ...           0.388880   \n",
       "13  {'alpha': 1e-05, 'batch_size': 50, 'dr_rate': ...  ...           0.345730   \n",
       "14  {'alpha': 1e-05, 'batch_size': 50, 'dr_rate': ...  ...           0.586399   \n",
       "15  {'alpha': 1e-05, 'batch_size': 50, 'dr_rate': ...  ...           0.617422   \n",
       "\n",
       "    split2_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0            0.259065         0.251375        0.025887               16   \n",
       "1            0.513429         0.525485        0.058435                9   \n",
       "2            0.506078         0.426300        0.062576               13   \n",
       "3            0.838214         0.581501        0.181795                6   \n",
       "4            0.417745         0.373630        0.037740               15   \n",
       "5            0.428267         0.391008        0.026495               14   \n",
       "6            0.686201         0.585891        0.105563                5   \n",
       "7            0.402893         0.489728        0.063736               12   \n",
       "8            0.619205         0.510466        0.076890               11   \n",
       "9            0.573849         0.632629        0.056697                1   \n",
       "10           0.580553         0.531478        0.045034                8   \n",
       "11           0.447500         0.590082        0.157925                3   \n",
       "12           0.506881         0.589210        0.205593                4   \n",
       "13           0.506573         0.522480        0.151229               10   \n",
       "14           0.532717         0.559137        0.021924                7   \n",
       "15           0.608839         0.599471        0.019632                2   \n",
       "\n",
       "    split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0             0.278121            0.217265            0.259884   \n",
       "1             0.601711            0.461010            0.514090   \n",
       "2             0.418713            0.353548            0.506415   \n",
       "3             0.440532            0.465411            0.838661   \n",
       "4             0.377746            0.325896            0.418839   \n",
       "5             0.368546            0.376059            0.428220   \n",
       "6             0.630931            0.440430            0.686590   \n",
       "7             0.554464            0.511867            0.402699   \n",
       "8             0.456282            0.455923            0.619940   \n",
       "9             0.708483            0.614910            0.574878   \n",
       "10            0.542517            0.471699            0.582153   \n",
       "11            0.810570            0.512502            0.446830   \n",
       "12            0.871917            0.388714            0.507388   \n",
       "13            0.715316            0.345507            0.505521   \n",
       "14            0.559606            0.586277            0.532203   \n",
       "15            0.572908            0.616805            0.607930   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "0           0.251757         0.025500  \n",
       "1           0.525604         0.058015  \n",
       "2           0.426225         0.062633  \n",
       "3           0.581535         0.182099  \n",
       "4           0.374160         0.038029  \n",
       "5           0.390942         0.026538  \n",
       "6           0.585984         0.105401  \n",
       "7           0.489677         0.063914  \n",
       "8           0.510715         0.077234  \n",
       "9           0.632757         0.055985  \n",
       "10          0.532123         0.045688  \n",
       "11          0.589967         0.158277  \n",
       "12          0.589340         0.205602  \n",
       "13          0.522115         0.151429  \n",
       "14          0.559362         0.022077  \n",
       "15          0.599214         0.018951  \n",
       "\n",
       "[16 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib.pyplot' has no attribute 'Ylabel'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\amane\\OneDrive\\python\\proto2020\\AE.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='file://c:\\Users\\amane\\OneDrive\\python\\proto2020\\AE.py?line=329'>330</a>\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpcolormesh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnpresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     <a href='file://c:\\Users\\amane\\OneDrive\\python\\proto2020\\AE.py?line=330'>331</a>\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'3rd Gridsearch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> <a href='file://c:\\Users\\amane\\OneDrive\\python\\proto2020\\AE.py?line=331'>332</a>\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mYlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"alpha\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     <a href='file://c:\\Users\\amane\\OneDrive\\python\\proto2020\\AE.py?line=332'>333</a>\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alpha'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alpha'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     <a href='file://c:\\Users\\amane\\OneDrive\\python\\proto2020\\AE.py?line=333'>334</a>\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Larning Rate\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'matplotlib.pyplot' has no attribute 'Ylabel'"
     ]
    }
   ],
   "source": [
    "# グリッドサーチ用コード\n",
    "\n",
    "# パラメータ空間の定義\n",
    "def gs_param():\n",
    "    pm = {\n",
    "        'alpha' : [1e-02,1e-03,1e-04,1e-05],\n",
    "        'lr':[0.1,0.05,0.025,0.01],\n",
    "        'dr_rate':[0.2],\n",
    "        'batch_size':[50],\n",
    "        'epochs':[10]\n",
    "    }\n",
    "    return pm\n",
    "\n",
    "#SklearnでラップしたAEを生成\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "ae_sklearn = KerasClassifier(\n",
    "    build_fn = ae,\n",
    "    input_dim = X_train_ae.shape[1],\n",
    "    encode_dim = encode_dim,\n",
    "    lr = lr,\n",
    "    alpha = alpha,\n",
    "    dr_rate = dr_rate\n",
    ")\n",
    "\n",
    "#グリッドサーチ\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(\n",
    "    estimator = ae_sklearn,\n",
    "    param_grid = gs_param(),\n",
    "    return_train_score = True,\n",
    "    cv = 3,\n",
    "    verbose = 2 \n",
    ")\n",
    "X_train_ae = scaler.fit_transform(X_train_ae)   #スケール変換\n",
    "grid.fit(X_train_ae,X_train_ae)\n",
    "\n",
    "#レポートの表示\n",
    "print('Gridsearch is over!')\n",
    "print(\"Best parameters :{}\".format(grid.best_params_))\n",
    "print(\"Best cross-validation score :{}\".format(grid.best_score_))\n",
    "\n",
    "#テスト結果の一覧表示(データフレーム使用)\n",
    "import pandas as pd\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    "display(results)\n",
    "\n",
    "#Dropout = 0.2の時のヒートマップを描画\n",
    "pm = gs_param()\n",
    "npresult = np.array(grid.cv_results_['mean_test_score']).reshape(4,4)\n",
    "plt.pcolormesh(npresult)\n",
    "plt.title('3rd Gridsearch')\n",
    "plt.Ylabel(\"alpha\")\n",
    "plt.yticks(np.arange(len(pm['alpha'])),pm['alpha'])\n",
    "plt.xlabel(\"Larning Rate\")\n",
    "plt.xticks(np.arange(len(pm['lr'])),pm['lr'])\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n",
       "<svg height=\"277.314375pt\" version=\"1.1\" viewBox=\"0 0 394.786375 277.314375\" width=\"394.786375pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       " <defs>\r\n",
       "  <style type=\"text/css\">\r\n",
       "*{stroke-linecap:butt;stroke-linejoin:round;}\r\n",
       "  </style>\r\n",
       " </defs>\r\n",
       " <g id=\"figure_1\">\r\n",
       "  <g id=\"patch_1\">\r\n",
       "   <path d=\"M 0 277.314375 \r\n",
       "L 394.786375 277.314375 \r\n",
       "L 394.786375 0 \r\n",
       "L 0 0 \r\n",
       "z\r\n",
       "\" style=\"fill:none;\"/>\r\n",
       "  </g>\r\n",
       "  <g id=\"axes_1\">\r\n",
       "   <g id=\"patch_2\">\r\n",
       "    <path d=\"M 62.86875 239.758125 \r\n",
       "L 330.70875 239.758125 \r\n",
       "L 330.70875 22.318125 \r\n",
       "L 62.86875 22.318125 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"QuadMesh_1\">\r\n",
       "    <path clip-path=\"url(#p0798b61736)\" d=\"M 62.86875 239.758125 \r\n",
       "L 129.82875 239.758125 \r\n",
       "L 129.82875 185.398125 \r\n",
       "L 62.86875 185.398125 \r\n",
       "L 62.86875 239.758125 \r\n",
       "\" style=\"fill:#440154;\"/>\r\n",
       "    <path clip-path=\"url(#p0798b61736)\" d=\"M 129.82875 239.758125 \r\n",
       "L 196.78875 239.758125 \r\n",
       "L 196.78875 185.398125 \r\n",
       "L 129.82875 185.398125 \r\n",
       "L 129.82875 239.758125 \r\n",
       "\" style=\"fill:#4ec36b;\"/>\r\n",
       "    <path clip-path=\"url(#p0798b61736)\" d=\"M 196.78875 239.758125 \r\n",
       "L 263.74875 239.758125 \r\n",
       "L 263.74875 185.398125 \r\n",
       "L 196.78875 185.398125 \r\n",
       "L 196.78875 239.758125 \r\n",
       "\" style=\"fill:#24868e;\"/>\r\n",
       "    <path clip-path=\"url(#p0798b61736)\" d=\"M 263.74875 239.758125 \r\n",
       "L 330.70875 239.758125 \r\n",
       "L 330.70875 185.398125 \r\n",
       "L 263.74875 185.398125 \r\n",
       "L 263.74875 239.758125 \r\n",
       "\" style=\"fill:#a5db36;\"/>\r\n",
       "    <path clip-path=\"url(#p0798b61736)\" d=\"M 62.86875 185.398125 \r\n",
       "L 129.82875 185.398125 \r\n",
       "L 129.82875 131.038125 \r\n",
       "L 62.86875 131.038125 \r\n",
       "L 62.86875 185.398125 \r\n",
       "\" style=\"fill:#32658e;\"/>\r\n",
       "    <path clip-path=\"url(#p0798b61736)\" d=\"M 129.82875 185.398125 \r\n",
       "L 196.78875 185.398125 \r\n",
       "L 196.78875 131.038125 \r\n",
       "L 129.82875 131.038125 \r\n",
       "L 129.82875 185.398125 \r\n",
       "\" style=\"fill:#2d708e;\"/>\r\n",
       "    <path clip-path=\"url(#p0798b61736)\" d=\"M 196.78875 185.398125 \r\n",
       "L 263.74875 185.398125 \r\n",
       "L 263.74875 131.038125 \r\n",
       "L 196.78875 131.038125 \r\n",
       "L 196.78875 185.398125 \r\n",
       "\" style=\"fill:#addc30;\"/>\r\n",
       "    <path clip-path=\"url(#p0798b61736)\" d=\"M 263.74875 185.398125 \r\n",
       "L 330.70875 185.398125 \r\n",
       "L 330.70875 131.038125 \r\n",
       "L 263.74875 131.038125 \r\n",
       "L 263.74875 185.398125 \r\n",
       "\" style=\"fill:#28ae80;\"/>\r\n",
       "    <path clip-path=\"url(#p0798b61736)\" d=\"M 62.86875 131.038125 \r\n",
       "L 129.82875 131.038125 \r\n",
       "L 129.82875 76.678125 \r\n",
       "L 62.86875 76.678125 \r\n",
       "L 62.86875 131.038125 \r\n",
       "\" style=\"fill:#3aba76;\"/>\r\n",
       "    <path clip-path=\"url(#p0798b61736)\" d=\"M 129.82875 131.038125 \r\n",
       "L 196.78875 131.038125 \r\n",
       "L 196.78875 76.678125 \r\n",
       "L 129.82875 76.678125 \r\n",
       "L 129.82875 131.038125 \r\n",
       "\" style=\"fill:#fde725;\"/>\r\n",
       "    <path clip-path=\"url(#p0798b61736)\" d=\"M 196.78875 131.038125 \r\n",
       "L 263.74875 131.038125 \r\n",
       "L 263.74875 76.678125 \r\n",
       "L 196.78875 76.678125 \r\n",
       "L 196.78875 131.038125 \r\n",
       "\" style=\"fill:#56c667;\"/>\r\n",
       "    <path clip-path=\"url(#p0798b61736)\" d=\"M 263.74875 131.038125 \r\n",
       "L 330.70875 131.038125 \r\n",
       "L 330.70875 76.678125 \r\n",
       "L 263.74875 76.678125 \r\n",
       "L 263.74875 131.038125 \r\n",
       "\" style=\"fill:#b5de2b;\"/>\r\n",
       "    <path clip-path=\"url(#p0798b61736)\" d=\"M 62.86875 76.678125 \r\n",
       "L 129.82875 76.678125 \r\n",
       "L 129.82875 22.318125 \r\n",
       "L 62.86875 22.318125 \r\n",
       "L 62.86875 76.678125 \r\n",
       "\" style=\"fill:#b2dd2d;\"/>\r\n",
       "    <path clip-path=\"url(#p0798b61736)\" d=\"M 129.82875 76.678125 \r\n",
       "L 196.78875 76.678125 \r\n",
       "L 196.78875 22.318125 \r\n",
       "L 129.82875 22.318125 \r\n",
       "L 129.82875 76.678125 \r\n",
       "\" style=\"fill:#4ac16d;\"/>\r\n",
       "    <path clip-path=\"url(#p0798b61736)\" d=\"M 196.78875 76.678125 \r\n",
       "L 263.74875 76.678125 \r\n",
       "L 263.74875 22.318125 \r\n",
       "L 196.78875 22.318125 \r\n",
       "L 196.78875 76.678125 \r\n",
       "\" style=\"fill:#7fd34e;\"/>\r\n",
       "    <path clip-path=\"url(#p0798b61736)\" d=\"M 263.74875 76.678125 \r\n",
       "L 330.70875 76.678125 \r\n",
       "L 330.70875 22.318125 \r\n",
       "L 263.74875 22.318125 \r\n",
       "L 263.74875 76.678125 \r\n",
       "\" style=\"fill:#c5e021;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"matplotlib.axis_1\">\r\n",
       "    <g id=\"xtick_1\">\r\n",
       "     <g id=\"line2d_1\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L 0 3.5 \r\n",
       "\" id=\"m73b5dabf46\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.86875\" xlink:href=\"#m73b5dabf46\" y=\"239.758125\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_1\">\r\n",
       "      <!-- 0.1 -->\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 31.78125 66.40625 \r\n",
       "Q 24.171875 66.40625 20.328125 58.90625 \r\n",
       "Q 16.5 51.421875 16.5 36.375 \r\n",
       "Q 16.5 21.390625 20.328125 13.890625 \r\n",
       "Q 24.171875 6.390625 31.78125 6.390625 \r\n",
       "Q 39.453125 6.390625 43.28125 13.890625 \r\n",
       "Q 47.125 21.390625 47.125 36.375 \r\n",
       "Q 47.125 51.421875 43.28125 58.90625 \r\n",
       "Q 39.453125 66.40625 31.78125 66.40625 \r\n",
       "z\r\n",
       "M 31.78125 74.21875 \r\n",
       "Q 44.046875 74.21875 50.515625 64.515625 \r\n",
       "Q 56.984375 54.828125 56.984375 36.375 \r\n",
       "Q 56.984375 17.96875 50.515625 8.265625 \r\n",
       "Q 44.046875 -1.421875 31.78125 -1.421875 \r\n",
       "Q 19.53125 -1.421875 13.0625 8.265625 \r\n",
       "Q 6.59375 17.96875 6.59375 36.375 \r\n",
       "Q 6.59375 54.828125 13.0625 64.515625 \r\n",
       "Q 19.53125 74.21875 31.78125 74.21875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-48\"/>\r\n",
       "       <path d=\"M 10.6875 12.40625 \r\n",
       "L 21 12.40625 \r\n",
       "L 21 0 \r\n",
       "L 10.6875 0 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-46\"/>\r\n",
       "       <path d=\"M 12.40625 8.296875 \r\n",
       "L 28.515625 8.296875 \r\n",
       "L 28.515625 63.921875 \r\n",
       "L 10.984375 60.40625 \r\n",
       "L 10.984375 69.390625 \r\n",
       "L 28.421875 72.90625 \r\n",
       "L 38.28125 72.90625 \r\n",
       "L 38.28125 8.296875 \r\n",
       "L 54.390625 8.296875 \r\n",
       "L 54.390625 0 \r\n",
       "L 12.40625 0 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-49\"/>\r\n",
       "      </defs>\r\n",
       "      <g transform=\"translate(54.917188 254.356562)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_2\">\r\n",
       "     <g id=\"line2d_2\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"129.82875\" xlink:href=\"#m73b5dabf46\" y=\"239.758125\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_2\">\r\n",
       "      <!-- 0.05 -->\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 10.796875 72.90625 \r\n",
       "L 49.515625 72.90625 \r\n",
       "L 49.515625 64.59375 \r\n",
       "L 19.828125 64.59375 \r\n",
       "L 19.828125 46.734375 \r\n",
       "Q 21.96875 47.46875 24.109375 47.828125 \r\n",
       "Q 26.265625 48.1875 28.421875 48.1875 \r\n",
       "Q 40.625 48.1875 47.75 41.5 \r\n",
       "Q 54.890625 34.8125 54.890625 23.390625 \r\n",
       "Q 54.890625 11.625 47.5625 5.09375 \r\n",
       "Q 40.234375 -1.421875 26.90625 -1.421875 \r\n",
       "Q 22.3125 -1.421875 17.546875 -0.640625 \r\n",
       "Q 12.796875 0.140625 7.71875 1.703125 \r\n",
       "L 7.71875 11.625 \r\n",
       "Q 12.109375 9.234375 16.796875 8.0625 \r\n",
       "Q 21.484375 6.890625 26.703125 6.890625 \r\n",
       "Q 35.15625 6.890625 40.078125 11.328125 \r\n",
       "Q 45.015625 15.765625 45.015625 23.390625 \r\n",
       "Q 45.015625 31 40.078125 35.4375 \r\n",
       "Q 35.15625 39.890625 26.703125 39.890625 \r\n",
       "Q 22.75 39.890625 18.8125 39.015625 \r\n",
       "Q 14.890625 38.140625 10.796875 36.28125 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-53\"/>\r\n",
       "      </defs>\r\n",
       "      <g transform=\"translate(118.695938 254.356562)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_3\">\r\n",
       "     <g id=\"line2d_3\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"196.78875\" xlink:href=\"#m73b5dabf46\" y=\"239.758125\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_3\">\r\n",
       "      <!-- 0.025 -->\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 19.1875 8.296875 \r\n",
       "L 53.609375 8.296875 \r\n",
       "L 53.609375 0 \r\n",
       "L 7.328125 0 \r\n",
       "L 7.328125 8.296875 \r\n",
       "Q 12.9375 14.109375 22.625 23.890625 \r\n",
       "Q 32.328125 33.6875 34.8125 36.53125 \r\n",
       "Q 39.546875 41.84375 41.421875 45.53125 \r\n",
       "Q 43.3125 49.21875 43.3125 52.78125 \r\n",
       "Q 43.3125 58.59375 39.234375 62.25 \r\n",
       "Q 35.15625 65.921875 28.609375 65.921875 \r\n",
       "Q 23.96875 65.921875 18.8125 64.3125 \r\n",
       "Q 13.671875 62.703125 7.8125 59.421875 \r\n",
       "L 7.8125 69.390625 \r\n",
       "Q 13.765625 71.78125 18.9375 73 \r\n",
       "Q 24.125 74.21875 28.421875 74.21875 \r\n",
       "Q 39.75 74.21875 46.484375 68.546875 \r\n",
       "Q 53.21875 62.890625 53.21875 53.421875 \r\n",
       "Q 53.21875 48.921875 51.53125 44.890625 \r\n",
       "Q 49.859375 40.875 45.40625 35.40625 \r\n",
       "Q 44.1875 33.984375 37.640625 27.21875 \r\n",
       "Q 31.109375 20.453125 19.1875 8.296875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-50\"/>\r\n",
       "      </defs>\r\n",
       "      <g transform=\"translate(182.474688 254.356562)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-50\"/>\r\n",
       "       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-53\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_4\">\r\n",
       "     <g id=\"line2d_4\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"263.74875\" xlink:href=\"#m73b5dabf46\" y=\"239.758125\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_4\">\r\n",
       "      <!-- 0.01 -->\r\n",
       "      <g transform=\"translate(252.615938 254.356562)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-49\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"text_5\">\r\n",
       "     <!-- Larning Rate -->\r\n",
       "     <defs>\r\n",
       "      <path d=\"M 9.8125 72.90625 \r\n",
       "L 19.671875 72.90625 \r\n",
       "L 19.671875 8.296875 \r\n",
       "L 55.171875 8.296875 \r\n",
       "L 55.171875 0 \r\n",
       "L 9.8125 0 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-76\"/>\r\n",
       "      <path d=\"M 34.28125 27.484375 \r\n",
       "Q 23.390625 27.484375 19.1875 25 \r\n",
       "Q 14.984375 22.515625 14.984375 16.5 \r\n",
       "Q 14.984375 11.71875 18.140625 8.90625 \r\n",
       "Q 21.296875 6.109375 26.703125 6.109375 \r\n",
       "Q 34.1875 6.109375 38.703125 11.40625 \r\n",
       "Q 43.21875 16.703125 43.21875 25.484375 \r\n",
       "L 43.21875 27.484375 \r\n",
       "z\r\n",
       "M 52.203125 31.203125 \r\n",
       "L 52.203125 0 \r\n",
       "L 43.21875 0 \r\n",
       "L 43.21875 8.296875 \r\n",
       "Q 40.140625 3.328125 35.546875 0.953125 \r\n",
       "Q 30.953125 -1.421875 24.3125 -1.421875 \r\n",
       "Q 15.921875 -1.421875 10.953125 3.296875 \r\n",
       "Q 6 8.015625 6 15.921875 \r\n",
       "Q 6 25.140625 12.171875 29.828125 \r\n",
       "Q 18.359375 34.515625 30.609375 34.515625 \r\n",
       "L 43.21875 34.515625 \r\n",
       "L 43.21875 35.40625 \r\n",
       "Q 43.21875 41.609375 39.140625 45 \r\n",
       "Q 35.0625 48.390625 27.6875 48.390625 \r\n",
       "Q 23 48.390625 18.546875 47.265625 \r\n",
       "Q 14.109375 46.140625 10.015625 43.890625 \r\n",
       "L 10.015625 52.203125 \r\n",
       "Q 14.9375 54.109375 19.578125 55.046875 \r\n",
       "Q 24.21875 56 28.609375 56 \r\n",
       "Q 40.484375 56 46.34375 49.84375 \r\n",
       "Q 52.203125 43.703125 52.203125 31.203125 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-97\"/>\r\n",
       "      <path d=\"M 41.109375 46.296875 \r\n",
       "Q 39.59375 47.171875 37.8125 47.578125 \r\n",
       "Q 36.03125 48 33.890625 48 \r\n",
       "Q 26.265625 48 22.1875 43.046875 \r\n",
       "Q 18.109375 38.09375 18.109375 28.8125 \r\n",
       "L 18.109375 0 \r\n",
       "L 9.078125 0 \r\n",
       "L 9.078125 54.6875 \r\n",
       "L 18.109375 54.6875 \r\n",
       "L 18.109375 46.1875 \r\n",
       "Q 20.953125 51.171875 25.484375 53.578125 \r\n",
       "Q 30.03125 56 36.53125 56 \r\n",
       "Q 37.453125 56 38.578125 55.875 \r\n",
       "Q 39.703125 55.765625 41.0625 55.515625 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-114\"/>\r\n",
       "      <path d=\"M 54.890625 33.015625 \r\n",
       "L 54.890625 0 \r\n",
       "L 45.90625 0 \r\n",
       "L 45.90625 32.71875 \r\n",
       "Q 45.90625 40.484375 42.875 44.328125 \r\n",
       "Q 39.84375 48.1875 33.796875 48.1875 \r\n",
       "Q 26.515625 48.1875 22.3125 43.546875 \r\n",
       "Q 18.109375 38.921875 18.109375 30.90625 \r\n",
       "L 18.109375 0 \r\n",
       "L 9.078125 0 \r\n",
       "L 9.078125 54.6875 \r\n",
       "L 18.109375 54.6875 \r\n",
       "L 18.109375 46.1875 \r\n",
       "Q 21.34375 51.125 25.703125 53.5625 \r\n",
       "Q 30.078125 56 35.796875 56 \r\n",
       "Q 45.21875 56 50.046875 50.171875 \r\n",
       "Q 54.890625 44.34375 54.890625 33.015625 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-110\"/>\r\n",
       "      <path d=\"M 9.421875 54.6875 \r\n",
       "L 18.40625 54.6875 \r\n",
       "L 18.40625 0 \r\n",
       "L 9.421875 0 \r\n",
       "z\r\n",
       "M 9.421875 75.984375 \r\n",
       "L 18.40625 75.984375 \r\n",
       "L 18.40625 64.59375 \r\n",
       "L 9.421875 64.59375 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-105\"/>\r\n",
       "      <path d=\"M 45.40625 27.984375 \r\n",
       "Q 45.40625 37.75 41.375 43.109375 \r\n",
       "Q 37.359375 48.484375 30.078125 48.484375 \r\n",
       "Q 22.859375 48.484375 18.828125 43.109375 \r\n",
       "Q 14.796875 37.75 14.796875 27.984375 \r\n",
       "Q 14.796875 18.265625 18.828125 12.890625 \r\n",
       "Q 22.859375 7.515625 30.078125 7.515625 \r\n",
       "Q 37.359375 7.515625 41.375 12.890625 \r\n",
       "Q 45.40625 18.265625 45.40625 27.984375 \r\n",
       "z\r\n",
       "M 54.390625 6.78125 \r\n",
       "Q 54.390625 -7.171875 48.1875 -13.984375 \r\n",
       "Q 42 -20.796875 29.203125 -20.796875 \r\n",
       "Q 24.46875 -20.796875 20.265625 -20.09375 \r\n",
       "Q 16.0625 -19.390625 12.109375 -17.921875 \r\n",
       "L 12.109375 -9.1875 \r\n",
       "Q 16.0625 -11.328125 19.921875 -12.34375 \r\n",
       "Q 23.78125 -13.375 27.78125 -13.375 \r\n",
       "Q 36.625 -13.375 41.015625 -8.765625 \r\n",
       "Q 45.40625 -4.15625 45.40625 5.171875 \r\n",
       "L 45.40625 9.625 \r\n",
       "Q 42.625 4.78125 38.28125 2.390625 \r\n",
       "Q 33.9375 0 27.875 0 \r\n",
       "Q 17.828125 0 11.671875 7.65625 \r\n",
       "Q 5.515625 15.328125 5.515625 27.984375 \r\n",
       "Q 5.515625 40.671875 11.671875 48.328125 \r\n",
       "Q 17.828125 56 27.875 56 \r\n",
       "Q 33.9375 56 38.28125 53.609375 \r\n",
       "Q 42.625 51.21875 45.40625 46.390625 \r\n",
       "L 45.40625 54.6875 \r\n",
       "L 54.390625 54.6875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-103\"/>\r\n",
       "      <path id=\"DejaVuSans-32\"/>\r\n",
       "      <path d=\"M 44.390625 34.1875 \r\n",
       "Q 47.5625 33.109375 50.5625 29.59375 \r\n",
       "Q 53.5625 26.078125 56.59375 19.921875 \r\n",
       "L 66.609375 0 \r\n",
       "L 56 0 \r\n",
       "L 46.6875 18.703125 \r\n",
       "Q 43.0625 26.03125 39.671875 28.421875 \r\n",
       "Q 36.28125 30.8125 30.421875 30.8125 \r\n",
       "L 19.671875 30.8125 \r\n",
       "L 19.671875 0 \r\n",
       "L 9.8125 0 \r\n",
       "L 9.8125 72.90625 \r\n",
       "L 32.078125 72.90625 \r\n",
       "Q 44.578125 72.90625 50.734375 67.671875 \r\n",
       "Q 56.890625 62.453125 56.890625 51.90625 \r\n",
       "Q 56.890625 45.015625 53.6875 40.46875 \r\n",
       "Q 50.484375 35.9375 44.390625 34.1875 \r\n",
       "z\r\n",
       "M 19.671875 64.796875 \r\n",
       "L 19.671875 38.921875 \r\n",
       "L 32.078125 38.921875 \r\n",
       "Q 39.203125 38.921875 42.84375 42.21875 \r\n",
       "Q 46.484375 45.515625 46.484375 51.90625 \r\n",
       "Q 46.484375 58.296875 42.84375 61.546875 \r\n",
       "Q 39.203125 64.796875 32.078125 64.796875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-82\"/>\r\n",
       "      <path d=\"M 18.3125 70.21875 \r\n",
       "L 18.3125 54.6875 \r\n",
       "L 36.8125 54.6875 \r\n",
       "L 36.8125 47.703125 \r\n",
       "L 18.3125 47.703125 \r\n",
       "L 18.3125 18.015625 \r\n",
       "Q 18.3125 11.328125 20.140625 9.421875 \r\n",
       "Q 21.96875 7.515625 27.59375 7.515625 \r\n",
       "L 36.8125 7.515625 \r\n",
       "L 36.8125 0 \r\n",
       "L 27.59375 0 \r\n",
       "Q 17.1875 0 13.234375 3.875 \r\n",
       "Q 9.28125 7.765625 9.28125 18.015625 \r\n",
       "L 9.28125 47.703125 \r\n",
       "L 2.6875 47.703125 \r\n",
       "L 2.6875 54.6875 \r\n",
       "L 9.28125 54.6875 \r\n",
       "L 9.28125 70.21875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-116\"/>\r\n",
       "      <path d=\"M 56.203125 29.59375 \r\n",
       "L 56.203125 25.203125 \r\n",
       "L 14.890625 25.203125 \r\n",
       "Q 15.484375 15.921875 20.484375 11.0625 \r\n",
       "Q 25.484375 6.203125 34.421875 6.203125 \r\n",
       "Q 39.59375 6.203125 44.453125 7.46875 \r\n",
       "Q 49.3125 8.734375 54.109375 11.28125 \r\n",
       "L 54.109375 2.78125 \r\n",
       "Q 49.265625 0.734375 44.1875 -0.34375 \r\n",
       "Q 39.109375 -1.421875 33.890625 -1.421875 \r\n",
       "Q 20.796875 -1.421875 13.15625 6.1875 \r\n",
       "Q 5.515625 13.8125 5.515625 26.8125 \r\n",
       "Q 5.515625 40.234375 12.765625 48.109375 \r\n",
       "Q 20.015625 56 32.328125 56 \r\n",
       "Q 43.359375 56 49.78125 48.890625 \r\n",
       "Q 56.203125 41.796875 56.203125 29.59375 \r\n",
       "z\r\n",
       "M 47.21875 32.234375 \r\n",
       "Q 47.125 39.59375 43.09375 43.984375 \r\n",
       "Q 39.0625 48.390625 32.421875 48.390625 \r\n",
       "Q 24.90625 48.390625 20.390625 44.140625 \r\n",
       "Q 15.875 39.890625 15.1875 32.171875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-101\"/>\r\n",
       "     </defs>\r\n",
       "     <g transform=\"translate(165.018438 268.034687)scale(0.1 -0.1)\">\r\n",
       "      <use xlink:href=\"#DejaVuSans-76\"/>\r\n",
       "      <use x=\"55.712891\" xlink:href=\"#DejaVuSans-97\"/>\r\n",
       "      <use x=\"116.992188\" xlink:href=\"#DejaVuSans-114\"/>\r\n",
       "      <use x=\"156.355469\" xlink:href=\"#DejaVuSans-110\"/>\r\n",
       "      <use x=\"219.734375\" xlink:href=\"#DejaVuSans-105\"/>\r\n",
       "      <use x=\"247.517578\" xlink:href=\"#DejaVuSans-110\"/>\r\n",
       "      <use x=\"310.896484\" xlink:href=\"#DejaVuSans-103\"/>\r\n",
       "      <use x=\"374.373047\" xlink:href=\"#DejaVuSans-32\"/>\r\n",
       "      <use x=\"406.160156\" xlink:href=\"#DejaVuSans-82\"/>\r\n",
       "      <use x=\"473.392578\" xlink:href=\"#DejaVuSans-97\"/>\r\n",
       "      <use x=\"534.671875\" xlink:href=\"#DejaVuSans-116\"/>\r\n",
       "      <use x=\"573.880859\" xlink:href=\"#DejaVuSans-101\"/>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"matplotlib.axis_2\">\r\n",
       "    <g id=\"ytick_1\">\r\n",
       "     <g id=\"line2d_5\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L -3.5 0 \r\n",
       "\" id=\"mc040e40fff\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.86875\" xlink:href=\"#mc040e40fff\" y=\"239.758125\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_6\">\r\n",
       "      <!-- 0.01 -->\r\n",
       "      <g transform=\"translate(33.603125 243.557344)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-49\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_2\">\r\n",
       "     <g id=\"line2d_6\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.86875\" xlink:href=\"#mc040e40fff\" y=\"185.398125\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_7\">\r\n",
       "      <!-- 0.001 -->\r\n",
       "      <g transform=\"translate(27.240625 189.197344)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-49\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_3\">\r\n",
       "     <g id=\"line2d_7\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.86875\" xlink:href=\"#mc040e40fff\" y=\"131.038125\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_8\">\r\n",
       "      <!-- 0.0001 -->\r\n",
       "      <g transform=\"translate(20.878125 134.837344)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-49\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_4\">\r\n",
       "     <g id=\"line2d_8\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.86875\" xlink:href=\"#mc040e40fff\" y=\"76.678125\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_9\">\r\n",
       "      <!-- 1e-05 -->\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 4.890625 31.390625 \r\n",
       "L 31.203125 31.390625 \r\n",
       "L 31.203125 23.390625 \r\n",
       "L 4.890625 23.390625 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-45\"/>\r\n",
       "      </defs>\r\n",
       "      <g transform=\"translate(27.020313 80.477344)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-101\"/>\r\n",
       "       <use x=\"125.146484\" xlink:href=\"#DejaVuSans-45\"/>\r\n",
       "       <use x=\"161.230469\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"224.853516\" xlink:href=\"#DejaVuSans-53\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"text_10\">\r\n",
       "     <!-- alpha -->\r\n",
       "     <defs>\r\n",
       "      <path d=\"M 9.421875 75.984375 \r\n",
       "L 18.40625 75.984375 \r\n",
       "L 18.40625 0 \r\n",
       "L 9.421875 0 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-108\"/>\r\n",
       "      <path d=\"M 18.109375 8.203125 \r\n",
       "L 18.109375 -20.796875 \r\n",
       "L 9.078125 -20.796875 \r\n",
       "L 9.078125 54.6875 \r\n",
       "L 18.109375 54.6875 \r\n",
       "L 18.109375 46.390625 \r\n",
       "Q 20.953125 51.265625 25.265625 53.625 \r\n",
       "Q 29.59375 56 35.59375 56 \r\n",
       "Q 45.5625 56 51.78125 48.09375 \r\n",
       "Q 58.015625 40.1875 58.015625 27.296875 \r\n",
       "Q 58.015625 14.40625 51.78125 6.484375 \r\n",
       "Q 45.5625 -1.421875 35.59375 -1.421875 \r\n",
       "Q 29.59375 -1.421875 25.265625 0.953125 \r\n",
       "Q 20.953125 3.328125 18.109375 8.203125 \r\n",
       "z\r\n",
       "M 48.6875 27.296875 \r\n",
       "Q 48.6875 37.203125 44.609375 42.84375 \r\n",
       "Q 40.53125 48.484375 33.40625 48.484375 \r\n",
       "Q 26.265625 48.484375 22.1875 42.84375 \r\n",
       "Q 18.109375 37.203125 18.109375 27.296875 \r\n",
       "Q 18.109375 17.390625 22.1875 11.75 \r\n",
       "Q 26.265625 6.109375 33.40625 6.109375 \r\n",
       "Q 40.53125 6.109375 44.609375 11.75 \r\n",
       "Q 48.6875 17.390625 48.6875 27.296875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-112\"/>\r\n",
       "      <path d=\"M 54.890625 33.015625 \r\n",
       "L 54.890625 0 \r\n",
       "L 45.90625 0 \r\n",
       "L 45.90625 32.71875 \r\n",
       "Q 45.90625 40.484375 42.875 44.328125 \r\n",
       "Q 39.84375 48.1875 33.796875 48.1875 \r\n",
       "Q 26.515625 48.1875 22.3125 43.546875 \r\n",
       "Q 18.109375 38.921875 18.109375 30.90625 \r\n",
       "L 18.109375 0 \r\n",
       "L 9.078125 0 \r\n",
       "L 9.078125 75.984375 \r\n",
       "L 18.109375 75.984375 \r\n",
       "L 18.109375 46.1875 \r\n",
       "Q 21.34375 51.125 25.703125 53.5625 \r\n",
       "Q 30.078125 56 35.796875 56 \r\n",
       "Q 45.21875 56 50.046875 50.171875 \r\n",
       "Q 54.890625 44.34375 54.890625 33.015625 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-104\"/>\r\n",
       "     </defs>\r\n",
       "     <g transform=\"translate(14.798438 144.898281)rotate(-90)scale(0.1 -0.1)\">\r\n",
       "      <use xlink:href=\"#DejaVuSans-97\"/>\r\n",
       "      <use x=\"61.279297\" xlink:href=\"#DejaVuSans-108\"/>\r\n",
       "      <use x=\"89.0625\" xlink:href=\"#DejaVuSans-112\"/>\r\n",
       "      <use x=\"152.539062\" xlink:href=\"#DejaVuSans-104\"/>\r\n",
       "      <use x=\"215.917969\" xlink:href=\"#DejaVuSans-97\"/>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_3\">\r\n",
       "    <path d=\"M 62.86875 239.758125 \r\n",
       "L 62.86875 22.318125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_4\">\r\n",
       "    <path d=\"M 330.70875 239.758125 \r\n",
       "L 330.70875 22.318125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_5\">\r\n",
       "    <path d=\"M 62.86875 239.758125 \r\n",
       "L 330.70875 239.758125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_6\">\r\n",
       "    <path d=\"M 62.86875 22.318125 \r\n",
       "L 330.70875 22.318125 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"text_11\">\r\n",
       "    <!-- 3rd Gridsearch -->\r\n",
       "    <defs>\r\n",
       "     <path d=\"M 40.578125 39.3125 \r\n",
       "Q 47.65625 37.796875 51.625 33 \r\n",
       "Q 55.609375 28.21875 55.609375 21.1875 \r\n",
       "Q 55.609375 10.40625 48.1875 4.484375 \r\n",
       "Q 40.765625 -1.421875 27.09375 -1.421875 \r\n",
       "Q 22.515625 -1.421875 17.65625 -0.515625 \r\n",
       "Q 12.796875 0.390625 7.625 2.203125 \r\n",
       "L 7.625 11.71875 \r\n",
       "Q 11.71875 9.328125 16.59375 8.109375 \r\n",
       "Q 21.484375 6.890625 26.8125 6.890625 \r\n",
       "Q 36.078125 6.890625 40.9375 10.546875 \r\n",
       "Q 45.796875 14.203125 45.796875 21.1875 \r\n",
       "Q 45.796875 27.640625 41.28125 31.265625 \r\n",
       "Q 36.765625 34.90625 28.71875 34.90625 \r\n",
       "L 20.21875 34.90625 \r\n",
       "L 20.21875 43.015625 \r\n",
       "L 29.109375 43.015625 \r\n",
       "Q 36.375 43.015625 40.234375 45.921875 \r\n",
       "Q 44.09375 48.828125 44.09375 54.296875 \r\n",
       "Q 44.09375 59.90625 40.109375 62.90625 \r\n",
       "Q 36.140625 65.921875 28.71875 65.921875 \r\n",
       "Q 24.65625 65.921875 20.015625 65.03125 \r\n",
       "Q 15.375 64.15625 9.8125 62.3125 \r\n",
       "L 9.8125 71.09375 \r\n",
       "Q 15.4375 72.65625 20.34375 73.4375 \r\n",
       "Q 25.25 74.21875 29.59375 74.21875 \r\n",
       "Q 40.828125 74.21875 47.359375 69.109375 \r\n",
       "Q 53.90625 64.015625 53.90625 55.328125 \r\n",
       "Q 53.90625 49.265625 50.4375 45.09375 \r\n",
       "Q 46.96875 40.921875 40.578125 39.3125 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-51\"/>\r\n",
       "     <path d=\"M 45.40625 46.390625 \r\n",
       "L 45.40625 75.984375 \r\n",
       "L 54.390625 75.984375 \r\n",
       "L 54.390625 0 \r\n",
       "L 45.40625 0 \r\n",
       "L 45.40625 8.203125 \r\n",
       "Q 42.578125 3.328125 38.25 0.953125 \r\n",
       "Q 33.9375 -1.421875 27.875 -1.421875 \r\n",
       "Q 17.96875 -1.421875 11.734375 6.484375 \r\n",
       "Q 5.515625 14.40625 5.515625 27.296875 \r\n",
       "Q 5.515625 40.1875 11.734375 48.09375 \r\n",
       "Q 17.96875 56 27.875 56 \r\n",
       "Q 33.9375 56 38.25 53.625 \r\n",
       "Q 42.578125 51.265625 45.40625 46.390625 \r\n",
       "z\r\n",
       "M 14.796875 27.296875 \r\n",
       "Q 14.796875 17.390625 18.875 11.75 \r\n",
       "Q 22.953125 6.109375 30.078125 6.109375 \r\n",
       "Q 37.203125 6.109375 41.296875 11.75 \r\n",
       "Q 45.40625 17.390625 45.40625 27.296875 \r\n",
       "Q 45.40625 37.203125 41.296875 42.84375 \r\n",
       "Q 37.203125 48.484375 30.078125 48.484375 \r\n",
       "Q 22.953125 48.484375 18.875 42.84375 \r\n",
       "Q 14.796875 37.203125 14.796875 27.296875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-100\"/>\r\n",
       "     <path d=\"M 59.515625 10.40625 \r\n",
       "L 59.515625 29.984375 \r\n",
       "L 43.40625 29.984375 \r\n",
       "L 43.40625 38.09375 \r\n",
       "L 69.28125 38.09375 \r\n",
       "L 69.28125 6.78125 \r\n",
       "Q 63.578125 2.734375 56.6875 0.65625 \r\n",
       "Q 49.8125 -1.421875 42 -1.421875 \r\n",
       "Q 24.90625 -1.421875 15.25 8.5625 \r\n",
       "Q 5.609375 18.5625 5.609375 36.375 \r\n",
       "Q 5.609375 54.25 15.25 64.234375 \r\n",
       "Q 24.90625 74.21875 42 74.21875 \r\n",
       "Q 49.125 74.21875 55.546875 72.453125 \r\n",
       "Q 61.96875 70.703125 67.390625 67.28125 \r\n",
       "L 67.390625 56.78125 \r\n",
       "Q 61.921875 61.421875 55.765625 63.765625 \r\n",
       "Q 49.609375 66.109375 42.828125 66.109375 \r\n",
       "Q 29.4375 66.109375 22.71875 58.640625 \r\n",
       "Q 16.015625 51.171875 16.015625 36.375 \r\n",
       "Q 16.015625 21.625 22.71875 14.15625 \r\n",
       "Q 29.4375 6.6875 42.828125 6.6875 \r\n",
       "Q 48.046875 6.6875 52.140625 7.59375 \r\n",
       "Q 56.25 8.5 59.515625 10.40625 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-71\"/>\r\n",
       "     <path d=\"M 44.28125 53.078125 \r\n",
       "L 44.28125 44.578125 \r\n",
       "Q 40.484375 46.53125 36.375 47.5 \r\n",
       "Q 32.28125 48.484375 27.875 48.484375 \r\n",
       "Q 21.1875 48.484375 17.84375 46.4375 \r\n",
       "Q 14.5 44.390625 14.5 40.28125 \r\n",
       "Q 14.5 37.15625 16.890625 35.375 \r\n",
       "Q 19.28125 33.59375 26.515625 31.984375 \r\n",
       "L 29.59375 31.296875 \r\n",
       "Q 39.15625 29.25 43.1875 25.515625 \r\n",
       "Q 47.21875 21.78125 47.21875 15.09375 \r\n",
       "Q 47.21875 7.46875 41.1875 3.015625 \r\n",
       "Q 35.15625 -1.421875 24.609375 -1.421875 \r\n",
       "Q 20.21875 -1.421875 15.453125 -0.5625 \r\n",
       "Q 10.6875 0.296875 5.421875 2 \r\n",
       "L 5.421875 11.28125 \r\n",
       "Q 10.40625 8.6875 15.234375 7.390625 \r\n",
       "Q 20.0625 6.109375 24.8125 6.109375 \r\n",
       "Q 31.15625 6.109375 34.5625 8.28125 \r\n",
       "Q 37.984375 10.453125 37.984375 14.40625 \r\n",
       "Q 37.984375 18.0625 35.515625 20.015625 \r\n",
       "Q 33.0625 21.96875 24.703125 23.78125 \r\n",
       "L 21.578125 24.515625 \r\n",
       "Q 13.234375 26.265625 9.515625 29.90625 \r\n",
       "Q 5.8125 33.546875 5.8125 39.890625 \r\n",
       "Q 5.8125 47.609375 11.28125 51.796875 \r\n",
       "Q 16.75 56 26.8125 56 \r\n",
       "Q 31.78125 56 36.171875 55.265625 \r\n",
       "Q 40.578125 54.546875 44.28125 53.078125 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-115\"/>\r\n",
       "     <path d=\"M 48.78125 52.59375 \r\n",
       "L 48.78125 44.1875 \r\n",
       "Q 44.96875 46.296875 41.140625 47.34375 \r\n",
       "Q 37.3125 48.390625 33.40625 48.390625 \r\n",
       "Q 24.65625 48.390625 19.8125 42.84375 \r\n",
       "Q 14.984375 37.3125 14.984375 27.296875 \r\n",
       "Q 14.984375 17.28125 19.8125 11.734375 \r\n",
       "Q 24.65625 6.203125 33.40625 6.203125 \r\n",
       "Q 37.3125 6.203125 41.140625 7.25 \r\n",
       "Q 44.96875 8.296875 48.78125 10.40625 \r\n",
       "L 48.78125 2.09375 \r\n",
       "Q 45.015625 0.34375 40.984375 -0.53125 \r\n",
       "Q 36.96875 -1.421875 32.421875 -1.421875 \r\n",
       "Q 20.0625 -1.421875 12.78125 6.34375 \r\n",
       "Q 5.515625 14.109375 5.515625 27.296875 \r\n",
       "Q 5.515625 40.671875 12.859375 48.328125 \r\n",
       "Q 20.21875 56 33.015625 56 \r\n",
       "Q 37.15625 56 41.109375 55.140625 \r\n",
       "Q 45.0625 54.296875 48.78125 52.59375 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-99\"/>\r\n",
       "    </defs>\r\n",
       "    <g transform=\"translate(152.374688 16.318125)scale(0.12 -0.12)\">\r\n",
       "     <use xlink:href=\"#DejaVuSans-51\"/>\r\n",
       "     <use x=\"63.623047\" xlink:href=\"#DejaVuSans-114\"/>\r\n",
       "     <use x=\"102.986328\" xlink:href=\"#DejaVuSans-100\"/>\r\n",
       "     <use x=\"166.462891\" xlink:href=\"#DejaVuSans-32\"/>\r\n",
       "     <use x=\"198.25\" xlink:href=\"#DejaVuSans-71\"/>\r\n",
       "     <use x=\"275.740234\" xlink:href=\"#DejaVuSans-114\"/>\r\n",
       "     <use x=\"316.853516\" xlink:href=\"#DejaVuSans-105\"/>\r\n",
       "     <use x=\"344.636719\" xlink:href=\"#DejaVuSans-100\"/>\r\n",
       "     <use x=\"408.113281\" xlink:href=\"#DejaVuSans-115\"/>\r\n",
       "     <use x=\"460.212891\" xlink:href=\"#DejaVuSans-101\"/>\r\n",
       "     <use x=\"521.736328\" xlink:href=\"#DejaVuSans-97\"/>\r\n",
       "     <use x=\"583.015625\" xlink:href=\"#DejaVuSans-114\"/>\r\n",
       "     <use x=\"621.878906\" xlink:href=\"#DejaVuSans-99\"/>\r\n",
       "     <use x=\"676.859375\" xlink:href=\"#DejaVuSans-104\"/>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "  </g>\r\n",
       "  <g id=\"axes_2\">\r\n",
       "   <g id=\"patch_7\">\r\n",
       "    <path clip-path=\"url(#p985729c8fb)\" d=\"M 347.44875 239.758125 \r\n",
       "L 347.44875 238.90875 \r\n",
       "L 347.44875 23.1675 \r\n",
       "L 347.44875 22.318125 \r\n",
       "L 358.32075 22.318125 \r\n",
       "L 358.32075 23.1675 \r\n",
       "L 358.32075 238.90875 \r\n",
       "L 358.32075 239.758125 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;stroke:#ffffff;stroke-linejoin:miter;stroke-width:0.01;\"/>\r\n",
       "   </g>\r\n",
       "   <image height=\"217\" id=\"image9e714e798d\" transform=\"scale(1 -1)translate(0 -217)\" width=\"11\" x=\"347\" xlink:href=\"data:image/png;base64,\r\n",
       "iVBORw0KGgoAAAANSUhEUgAAAAsAAADZCAYAAAD2WsoCAAAABHNCSVQICAgIfAhkiAAAAWFJREFUaIHt2kFuwzAQQ1FpJOdkPUPvf5C26bZANnoLAuMiWRPEJ2dkO07mR30+x+Fnz5qn2rHnWufiMQvEgjGmMJdgiPOgNqjnHtVZQHLOid9t/BXH2niuHgGJ2cbdA+P8SpDFEOcgc8p5iDMtv/VMGLE2bIK0G8YM4iZtBDFy1VHALqcbxOSMAVMY6By7yNyyjZjzHds41+Lzxh0n+P/HTc4txg0Q79P9Ij4/33fcjTZtBMcNzMHqKoXRpA14REq2MUYuIDjPWEDrmZhNDBjUhmGcU3DAVBurfjpgVKyNJeIcRhPnNWHc5NxEvO8YUG4T1kZ9d8AoGYodWGGmNpa1kdo6amNPCphjFmfpmZwvacNWNLYbuaE85hc4x4ZSEpCW/5KA1DNekcg5tRu0/LbPwYCpG9Bj0KVAlp9OigU81o592YEF5wVfCLe83dtLfsgowbjgfZZigDMxL/kjkGD8AgQsgWhMNMxTAAAAAElFTkSuQmCC\" y=\"-22\"/>\r\n",
       "   <g id=\"matplotlib.axis_3\"/>\r\n",
       "   <g id=\"matplotlib.axis_4\">\r\n",
       "    <g id=\"ytick_5\">\r\n",
       "     <g id=\"line2d_9\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L 3.5 0 \r\n",
       "\" id=\"mfba9682627\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"358.32075\" xlink:href=\"#mfba9682627\" y=\"212.025871\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_12\">\r\n",
       "      <!-- 0.30 -->\r\n",
       "      <g transform=\"translate(365.32075 215.825089)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\r\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_6\">\r\n",
       "     <g id=\"line2d_10\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"358.32075\" xlink:href=\"#mfba9682627\" y=\"183.509472\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_13\">\r\n",
       "      <!-- 0.35 -->\r\n",
       "      <g transform=\"translate(365.32075 187.308691)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\r\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_7\">\r\n",
       "     <g id=\"line2d_11\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"358.32075\" xlink:href=\"#mfba9682627\" y=\"154.993074\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_14\">\r\n",
       "      <!-- 0.40 -->\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 37.796875 64.3125 \r\n",
       "L 12.890625 25.390625 \r\n",
       "L 37.796875 25.390625 \r\n",
       "z\r\n",
       "M 35.203125 72.90625 \r\n",
       "L 47.609375 72.90625 \r\n",
       "L 47.609375 25.390625 \r\n",
       "L 58.015625 25.390625 \r\n",
       "L 58.015625 17.1875 \r\n",
       "L 47.609375 17.1875 \r\n",
       "L 47.609375 0 \r\n",
       "L 37.796875 0 \r\n",
       "L 37.796875 17.1875 \r\n",
       "L 4.890625 17.1875 \r\n",
       "L 4.890625 26.703125 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-52\"/>\r\n",
       "      </defs>\r\n",
       "      <g transform=\"translate(365.32075 158.792292)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\r\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_8\">\r\n",
       "     <g id=\"line2d_12\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"358.32075\" xlink:href=\"#mfba9682627\" y=\"126.476675\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_15\">\r\n",
       "      <!-- 0.45 -->\r\n",
       "      <g transform=\"translate(365.32075 130.275894)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\r\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_9\">\r\n",
       "     <g id=\"line2d_13\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"358.32075\" xlink:href=\"#mfba9682627\" y=\"97.960276\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_16\">\r\n",
       "      <!-- 0.50 -->\r\n",
       "      <g transform=\"translate(365.32075 101.759495)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_10\">\r\n",
       "     <g id=\"line2d_14\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"358.32075\" xlink:href=\"#mfba9682627\" y=\"69.443878\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_17\">\r\n",
       "      <!-- 0.55 -->\r\n",
       "      <g transform=\"translate(365.32075 73.243097)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_11\">\r\n",
       "     <g id=\"line2d_15\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"358.32075\" xlink:href=\"#mfba9682627\" y=\"40.927479\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_18\">\r\n",
       "      <!-- 0.60 -->\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 33.015625 40.375 \r\n",
       "Q 26.375 40.375 22.484375 35.828125 \r\n",
       "Q 18.609375 31.296875 18.609375 23.390625 \r\n",
       "Q 18.609375 15.53125 22.484375 10.953125 \r\n",
       "Q 26.375 6.390625 33.015625 6.390625 \r\n",
       "Q 39.65625 6.390625 43.53125 10.953125 \r\n",
       "Q 47.40625 15.53125 47.40625 23.390625 \r\n",
       "Q 47.40625 31.296875 43.53125 35.828125 \r\n",
       "Q 39.65625 40.375 33.015625 40.375 \r\n",
       "z\r\n",
       "M 52.59375 71.296875 \r\n",
       "L 52.59375 62.3125 \r\n",
       "Q 48.875 64.0625 45.09375 64.984375 \r\n",
       "Q 41.3125 65.921875 37.59375 65.921875 \r\n",
       "Q 27.828125 65.921875 22.671875 59.328125 \r\n",
       "Q 17.53125 52.734375 16.796875 39.40625 \r\n",
       "Q 19.671875 43.65625 24.015625 45.921875 \r\n",
       "Q 28.375 48.1875 33.59375 48.1875 \r\n",
       "Q 44.578125 48.1875 50.953125 41.515625 \r\n",
       "Q 57.328125 34.859375 57.328125 23.390625 \r\n",
       "Q 57.328125 12.15625 50.6875 5.359375 \r\n",
       "Q 44.046875 -1.421875 33.015625 -1.421875 \r\n",
       "Q 20.359375 -1.421875 13.671875 8.265625 \r\n",
       "Q 6.984375 17.96875 6.984375 36.375 \r\n",
       "Q 6.984375 53.65625 15.1875 63.9375 \r\n",
       "Q 23.390625 74.21875 37.203125 74.21875 \r\n",
       "Q 40.921875 74.21875 44.703125 73.484375 \r\n",
       "Q 48.484375 72.75 52.59375 71.296875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-54\"/>\r\n",
       "      </defs>\r\n",
       "      <g transform=\"translate(365.32075 44.726698)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\r\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_8\">\r\n",
       "    <path d=\"M 347.44875 239.758125 \r\n",
       "L 347.44875 238.90875 \r\n",
       "L 347.44875 23.1675 \r\n",
       "L 347.44875 22.318125 \r\n",
       "L 358.32075 22.318125 \r\n",
       "L 358.32075 23.1675 \r\n",
       "L 358.32075 238.90875 \r\n",
       "L 358.32075 239.758125 \r\n",
       "z\r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "  </g>\r\n",
       " </g>\r\n",
       " <defs>\r\n",
       "  <clipPath id=\"p0798b61736\">\r\n",
       "   <rect height=\"217.44\" width=\"267.84\" x=\"62.86875\" y=\"22.318125\"/>\r\n",
       "  </clipPath>\r\n",
       "  <clipPath id=\"p985729c8fb\">\r\n",
       "   <rect height=\"217.44\" width=\"10.872\" x=\"347.44875\" y=\"22.318125\"/>\r\n",
       "  </clipPath>\r\n",
       " </defs>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pm = gs_param()\n",
    "npresult = np.array(grid.cv_results_['mean_test_score']).reshape(4,4)\n",
    "plt.pcolormesh(npresult)\n",
    "plt.title('3rd Gridsearch')\n",
    "plt.ylabel(\"alpha\")\n",
    "plt.yticks(np.arange(len(pm['alpha'])),pm['alpha'])\n",
    "plt.xlabel(\"Larning Rate\")\n",
    "plt.xticks(np.arange(len(pm['lr'])),pm['lr'])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1回目： alphaは1～0.01、lrは0.001～1e-06\n",
    "2回目： alpha1e-06,lr0.01～0.001\n",
    "3回目： alpha = 0.0001,lr = 0.05\n",
    "\n",
    "ただし全体的にaccuracyが低い\n",
    "学習曲線だけで見ればalpha = 1e-05,lr = 0.01が最高スコア"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
